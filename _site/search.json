[
  {
    "objectID": "series/R Basic/about.html",
    "href": "series/R Basic/about.html",
    "title": "R Basic",
    "section": "",
    "text": "In this section, I will introduce you to R Basics, Functions, and Datatypes.\nIn this part, you will learn to:\n\nAppreciate the rationale for data analysis using R.\nDefine objects and perform basic arithmetic and logical operations.\nUse pre-defined functions to perform operations on objects.\nDistinguish between various data types.\n\n\n\n\nTo complete this course, you should install R locally on your computer. We also highly recommend installing RStudio, an integrated development environment (IDE), to edit and test your code.\nIn order to complete some assignments in the course, you will need your own copy of R. You may also find it helpful to follow along with the course videos in R or RStudio.\nBoth R and RStudio can be freely downloaded and installed.\n\n\nYou need to install R before using RStudio, which is an interactive desktop environment.\nSelect base subdirectory in CRAN and click download.\nSelect all default choices in the installation process.\nWe recommend selecting English for language to help you better follow the course.\nYou can try using the R console, but for productivity purposes, we can switch to RStudio.\n\n\n\nYou can download the latest version of RStudio at the RStudio website.\nThe free desktop version is more than enough for this course.\nMake sure to choose the version for your own operating system.\nChoose “Yes” for all defaults in the installation process.\n\n\n\nThe free desktop version of RStudio can be launched like other applications on your computer.\nWhen you start RStudio for the first time, you will see three panes. The left pane shows you the R console. On the right, the top pane includes three tabs, while the bottom pane shows you five tabs, file, plots, packages, help, and viewer.\nYou can download a cheat sheet of the most common RStudio commands directly from RStudio by going to “Help -> Cheat Sheets -> RStudio IDE Cheat Sheet.”\n\n\n\nR was developed by statisticians and data analysts as an interactive environment for data analysis.\n\nSome of the advantages of R are that:\n\nit is free and open source;\nit has the capability to save scripts;\nthere are numerous resources for learning;\nit is easy for developers to share software implementation.\n\n\nExpressions are evaluated in the R console when you type the expression into the console and hit Return.\nA great advantage of R over point and click analysis software is that you can save your work as scripts.\n“Base R” is what you get after you first install R. Additional components are available via packages.\n\nIn RStudio, you can upload additional functions and datasets in addition to the base R functions and datasets that come with R automatically. A common way to do this is by installing packages, which often contain extra functions and datasets. For this course, there are a few packages you will need to install. You only need to install each individual package once, but after you install a package, there are other steps you have to do whenever you want to use something from that package.\nTo install a package, you use the code install.packages(\"package_name\", dependencies = TRUE).\nTo load a package, you use the code library(package_name).\nIf you also want to use a dataset from a package you have loaded, then you use the code data(dataset_name). To see the dataset, you can take the additional step of View(dataset_name).\n\n\nWe recommend installing packages through RStudio, rather than through R, and the code provided works in both R and RStudio. Once a package has been installed, it is technically added onto R (even if you use RStudio to install it), which is why packages must be re-installed when R is updated. However, since we use R through RStudio, any packages that are installed can be used in both R and RStudio, regardless of which one was used to install the packages.\n\n\nThe base version of R is quite minimal, but you can supplement its functions by installing additional packages.\nWe will be using tidyverse and dslabs packages for this course.\nInstall packages from R console: install.packages(\"pkg_name\")\n\nInstall packages from RStudio interface: Tools > Install Packages (allows autocomplete)\nOnce installed, we can use library(pkg_name) to load a package each time we want to use it\n\n\nIf you try to load a package with library(blahblah) and get a message like Error in library(blahblah) : there is no package called ‘blahblah’, it means you need to install that package first with install.packages().\nOn the DataCamp interface we use for some problems in the course, you cannot install additional packages. The problems have been set up with the packages you need to solve them.\nYou can add the option dependencies = TRUE, which tells R to install the other things that are necessary for the package or packages to run smoothly. Otherwise, you may need to install additional packages to unlock the full functionality of a package.\nThroughout the course materials and textbook, package names are in bold.\n\n\ninstall.packages(\"dslabs\") # to install a single package\ninstall.packages(c(\"tidyverse\", \"dslabs\")) # to install two packages at the same time\ninstalled.packages() # to see the list of all installed packages\n\n\n\n\nRStudio has many useful features as an R editor, including the ability to test code easily as we write scripts and several auto complete features.\n\nKeyboard shortcuts:\n\n\nSave a script: Ctrl+S on Windows and Command+S on Mac\n\nRun an entire script: Ctrl+Shift+Enter on Windows Command+Shift+Return on Mac, or click “Source” on the editor pane\n\nRun a single line of script: Ctrl+Enter on Windows and Command+Return on Mac while the cursor is pointing to that line, or select the chunk and click “run”\n\nOpen a new script: Ctrl+Shift+N on Windows and Command+Shift+N on Mac\n\n\n\n\n# Here is an example how to running commends while editing scripts\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\nmurders %>% \n  ggplot(aes(population, total, label=abb, color=region)) +\n  geom_label()\n\n\n\n\nTo define a variable, we may use the assignment symbol, <-.\n\n\n(1) type the variable name into the console and hit Return;\n\n\nuse the print() function by typing print(variable_name) and hitting Return.\n\n\n\nObjects are things that are stored in named containers in R. They can be variables, functions, etc.\nThe ls() function shows the names of the objects saved in your work space.\n\n\n# assigning values to variables\na <- 1\nb <- 1\nc <- -1\n\n# solving the quadratic equation\n(-b + sqrt(b^2 - 4*a*c))/(2*a)\n(-b - sqrt(b^2 - 4*a*c))/(2*a)\n\n\n\n\nIn general, to evaluate a function we need to use parentheses. If we type a function without parenthesis, R shows us the code for the function. Most functions also require an argument, that is, something to be written inside the parenthesis.\nTo access help files, we may use the help function, help(function_name), or write the question mark followed by the function name, ?function_name.\nThe help file shows you the arguments the function is expecting, some of which are required and some are optional. If an argument is optional, a default value is assigned with the equal sign. The args() function also shows the arguments a function needs.\nTo specify arguments, we use the equals sign. If no argument name is used, R assumes you’re entering arguments in the order shown in the help file.\nCreating and saving a script makes code much easier to execute.\nTo make your code more readable, use intuitive variable names and include comments (using the “#” symbol) to remind yourself why you wrote a particular line of code.\n\n\n\n\n\n\n\nNote\n\n\n\nThe code data(\"dataset_name\") and data(dataset_name) do the same thing. The code will work regardless of whether the quotes are present. It is a bit faster to leave out the quotes (as we do in the Code at the bottom of this page), so that is usually what we recommend, but it is your choice.\n\n\n\n\nThe function class() helps us determine the type of an object.\nData frames can be thought of as tables with rows representing observations and columns representing different variables.\nTo access data from columns of a data frame, we use the dollar sign symbol, $, which is called the accessor.\nA vector is an object consisting of several entries and can be a numeric vector, a character vector, or a logical vector.\nWe use quotes to distinguish between variable names and character strings.\nFactors are useful for storing categorical data, and are more memory efficient than storing characters.\n\n\n\n\n\n\n\nKnowledge Extension\n\n\n\n\n\n\n\n\nflowchart LR\n  A{Data Type}---> B[numeric]\n  A{Data Type}--->C[integer]\n  A{Data Type} --->D[complex]\n  A{Data Type}--->E[character]\n  A{Data Type}--->F[logical]\n\n\n\n\n\n\n\n\n\n\nExplanation:Numeric: all real numbers with or without decimal values. e.g. 1, 2, 8, 1.1.Integer(整数): specifies real values without decimal points. we use the suffixL to specify integer data.Complex: specify purely imaginary values in R. We use the suffix i to specify the imaginary part. e.g. 3 + 2i.Character:specify character or string values in a variable. '' for character variables; \"\" for string variables.Logical: is known as boolean data type. It can only have two values: TRUE and FALSE\n\n\n# loading the dslabs package and the murders dataset\nlibrary(dslabs)\ndata(murders)\n\n# determining that the murders dataset is of the \"data frame\" class\nclass(murders)\n# finding out more about the structure of the object\nstr(murders)\n# showing the first 6 lines of the dataset\nhead(murders)\n\n# using the accessor operator to obtain the population column\nmurders$population\n# displaying the variable names in the murders dataset\nnames(murders)\n# determining how many entries are in a vector\npop <- murders$population\nlength(pop)\n# vectors can be of class numeric and character\nclass(pop)\nclass(murders$state)\n\n# logical vectors are either TRUE or FALSE\nz <- 3 == 2\nz\nclass(z)\n\n# factors are another type of class\nclass(murders$region)\n# obtaining the levels of a factor\nlevels(murders$region)"
  },
  {
    "objectID": "series/R Basic/about.html#vectors",
    "href": "series/R Basic/about.html#vectors",
    "title": "R Basic",
    "section": "\n2.1 Vectors",
    "text": "2.1 Vectors\n\n2.1.1 Key points\n\nThe function c(), which stands for concatenate, is useful for creating vectors.\nAnother useful function for creating vectors is the seq() function, which generates sequences.\nSubsetting lets us access specific parts of a vector by using square brackets to access elements of a vector.\n\n2.1.2 Code\n\n# We may create vectors of class numeric or character with the concatenate function\ncodes <- c(380, 124, 818)\ncountry <- c(\"italy\", \"canada\", \"egypt\")\n\n# We can also name the elements of a numeric vector\n# Note that the two lines of code below have the same result\ncodes <- c(italy = 380, canada = 124, egypt = 818)\ncodes <- c(\"italy\" = 380, \"canada\" = 124, \"egypt\" = 818)\n\n# We can also name the elements of a numeric vector using the names() function\ncodes <- c(380, 124, 818)\ncountry <- c(\"italy\",\"canada\",\"egypt\")\nnames(codes) <- country\n\n# Using square brackets is useful for subsetting to access specific elements of a vector\ncodes[2]\ncodes[c(1,3)]\ncodes[1:2]\n\n# If the entries of a vector are named, they may be accessed by referring to their name\ncodes[\"canada\"]\ncodes[c(\"egypt\",\"italy\")]"
  },
  {
    "objectID": "series/R Basic/about.html#vector-coercion",
    "href": "series/R Basic/about.html#vector-coercion",
    "title": "R Basic",
    "section": "\n2.2 Vector Coercion",
    "text": "2.2 Vector Coercion\n\n2.2.1 Key Point\n\nIn general, coercion is an attempt by R to be flexible with data types by guessing what was meant when an entry does not match the expected. For example, when defining x as\n\n\n    x <- c(1, \"canada\", 3)\n\nR coerced the data into characters. It guessed that because you put a character string in the vector, you meant the 1 and 3 to actually be character strings, “1” and “3”.\n\nThe function as.character() turns numbers into characters.\nThe function as.numeric() turns characters into numbers.\nIn R, missing data is assigned the value NA.\n\n2.2.2 Question\n\nclass(3L) is integer ?\n3L-3 equals 0 ?"
  },
  {
    "objectID": "series/R Basic/about.html#sorting",
    "href": "series/R Basic/about.html#sorting",
    "title": "R Basic",
    "section": "\n2.3 Sorting",
    "text": "2.3 Sorting\n\n\n\n\n\n\n\n\n\nOriginal\nSort(按从小到大排列）\nOrder(Sort对应数字在原来数字排列中的顺序）\nRank(Original原来数字在Sort顺序中的排名）\n\n\n31\n4\n2\n3\n\n\n4\n15\n3\n1\n\n\n15\n31\n1\n2\n\n\n92\n65\n5\n5\n\n\n65\n92\n4\n4\n\n\n\n\n2.3.1 Key Points\n\nThe function sort() sorts a vector in increasing order.\nThe function order() produces the indices needed to obtain the sorted vector, e.g. a result of 2 3 1 5 4 means the sorted vector will be produced by listing the 2nd, 3rd, 1st, 5th, and then 4th item of the original vector.\nThe function rank() gives us the ranks of the items in the original vector.\nThe function max() returns the largest value, while which.max() returns the index of the largest value. The functions min() and which.min() work similarly for minimum values.\n\n2.3.2 Code\n\nlibrary(dslabs)\ndata(murders)\nsort(murders$total)\n\nx <- c(31, 4, 15, 92, 65)\nx\nsort(x)    # puts elements in order\n\nindex <- order(x)    # returns index that will put x in order\nx[index]    # rearranging by this index puts elements in order\norder(x)\n\nmurders$state[1:10]\nmurders$abb[1:10]\n\nindex <- order(murders$total)\nmurders$abb[index]    # order abbreviations by total murders\n\nmax(murders$total)    # highest number of total murders\ni_max <- which.max(murders$total)    # index with highest number of murders\nmurders$state[i_max]    # state name with highest number of total murders\n\nx <- c(31, 4, 15, 92, 65)\nx\nrank(x)    # returns ranks (smallest to largest)"
  },
  {
    "objectID": "series/R Basic/about.html#vector-arithmetic",
    "href": "series/R Basic/about.html#vector-arithmetic",
    "title": "R Basic",
    "section": "\n2.4 Vector Arithmetic",
    "text": "2.4 Vector Arithmetic\n\n2.4.1 Key Point\n\nIn R, arithmetic operation on vectors occur element-wise\n\n2.4.2 Code\n\n# The name of the state with the maximum population is found by doing the following\nmurders$state[which.max(murders$population)]\n\n# how to obtain the murder rate\nmurder_rate <- murders$total / murders$population * 100000\n\n# ordering the states by murder rate, in decreasing order\nmurders$state[order(murder_rate, decreasing=TRUE)]"
  },
  {
    "objectID": "series/R Basic/about.html#indexing",
    "href": "series/R Basic/about.html#indexing",
    "title": "R Basic",
    "section": "\n3.1 Indexing",
    "text": "3.1 Indexing\n\n3.1.1 Key Point\n\nWe can use logicals to index vectors.\nUsing the function sum()on a logical vector returns the number of entries that are true.\nThe logical operator “&” makes two logicals true only when they are both true.\n\n3.1.2 Code\n\n# defining murder rate as before\nmurder_rate <- murders$total / murders$population * 100000\n# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71\nindex <- murder_rate <= 0.71\n# determining which states have murder rates less than or equal to 0.71\nmurders$state[index]\n# calculating how many states have a murder rate less than or equal to 0.71\nsum(index)\n\n# creating the two logical vectors representing our conditions\nwest <- murders$region == \"West\"\nsafe <- murder_rate <= 1\n# defining an index and identifying states with both conditions true\nindex <- safe & west\nmurders$state[index]"
  },
  {
    "objectID": "series/R Basic/about.html#indexing-functions",
    "href": "series/R Basic/about.html#indexing-functions",
    "title": "R Basic",
    "section": "\n3.2 Indexing Functions",
    "text": "3.2 Indexing Functions\n\n3.2.1 Key Points\n\nThe function which() gives us the entries of a logical vector that are true.\nThe function match() looks for entries in a vector and returns the index needed to access them.\nWe use the function %in% if we want to know whether or not each element of a first vector is in a second vector.\n\n3.2.2 Code\n\nx <- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)\nwhich(x)    # returns indices that are TRUE\n\n# to determine the murder rate in Massachusetts we may do the following\nindex <- which(murders$state == \"Massachusetts\")\nindex\nmurder_rate[index]\n\n# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:\nindex <- match(c(\"New York\", \"Florida\", \"Texas\"), murders$state)\nindex\nmurders$state[index]\nmurder_rate[index]\n\nx <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\ny <- c(\"a\", \"d\", \"f\")\ny %in% x\n\n# to see if Boston, Dakota, and Washington are states\nc(\"Boston\", \"Dakota\", \"Washington\") %in% murders$state"
  },
  {
    "objectID": "series/R Basic/about.html#basic-data-wrangling",
    "href": "series/R Basic/about.html#basic-data-wrangling",
    "title": "R Basic",
    "section": "\n3.3 Basic Data Wrangling",
    "text": "3.3 Basic Data Wrangling\n\n3.3.1 Key Points\n\nTo change a data table by adding a new column, or changing an existing one, we use the mutate() function.\nTo filter the data by subsetting rows, we use the function filter().\nTo subset the data by selecting specific columns, we use the select() function.\nWe can perform a series of operations by sending the results of one function to another function using the pipe operator, %>%."
  },
  {
    "objectID": "series/R Basic/about.html#creating-data-frames",
    "href": "series/R Basic/about.html#creating-data-frames",
    "title": "R Basic",
    "section": "\n3.4 Creating Data Frames",
    "text": "3.4 Creating Data Frames\n\n3.4.1 Note\nThe default settings in R have changed as of version 4.0, and it is no longer necessary to include the code stringsAsFactors = FALSE in order to keep strings as characters. Putting the entries in quotes, as in the example, is adequate to keep strings as characters. The stringsAsFactors = FALSE code is useful in certain other situations, but you do not need to include it when you create data frames in this manner.\n\n3.4.2 Key Points\n\nWe can use the data.frame() function to create data frames.\nFormerly, the data.frame() function turned characters into factors by default. To avoid this, we could utilize the stringsAsFactors argument and set it equal to false. As of R 4.0, it is no longer necessary to include the stringsAsFactors argument, because R no longer turns characters into factors by default.\n\n3.4.3 Code\n\n# creating a data frame with stringAsFactors = FALSE\ngrades <- data.frame(names = c(\"John\", \"Juan\", \"Jean\", \"Yao\"), \n                     exam_1 = c(95, 80, 90, 85), \n                     exam_2 = c(90, 85, 85, 90),\n                     stringsAsFactors = FALSE)"
  },
  {
    "objectID": "series/R Basic/about.html#basic-plots",
    "href": "series/R Basic/about.html#basic-plots",
    "title": "R Basic",
    "section": "\n3.5 Basic Plots",
    "text": "3.5 Basic Plots\n\n3.5.1 Key Points\n\nWe can create a simple scatterplot using the function plot().\nHistograms are graphical summaries that give you a general overview of the types of values you have. In R, they can be produced using the hist() function.\nBoxplots provide a more compact summary of a distribution than a histogram and are more useful for comparing distributions. They can be produced using the boxplot() function.\n\n3.5.2 Code\n\nlibrary(dplyr)\nlibrary(dslabs)\ndata(\"murders\")\n\n\n# a simple scatterplot of total murders versus population\nx <- murders$population /10^6\ny <- murders$total\nplot(x, y)\n\n\n\n\n\n# a histogram of murder rates\nmurders <- mutate(murders, rate = total / population * 100000)\nhist(murders$rate)\n\n\n\n# boxplots of murder rates by region\nboxplot(rate~region, data = murders)"
  },
  {
    "objectID": "series/R Basic/about.html#the-summarize-function",
    "href": "series/R Basic/about.html#the-summarize-function",
    "title": "R Basic",
    "section": "\n3.6 The summarize function",
    "text": "3.6 The summarize function\n\n3.6.1 Key Points\n\nSummarizing data is an important part of data analysis.\nSome summary ststistics are the mean, median, and standard deviation.\nThe summarize() function from dplyr provides an easy way to compute summary statics.\n\n3.6.2 Code\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region\ns <- murders %>% \n  filter(region == \"West\") %>%\n  summarize(minimum = min(rate), \n            median = median(rate), \n            maximum = max(rate))\ns\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527\n\n# accessing the components with the accessor $\ns$median\n\n[1] 1.292453\n\ns$maximum\n\n[1] 3.629527\n\n# average rate unadjusted by population size\nmean(murders$rate)\n\n[1] 2.779125\n\n# average rate adjusted by population size\nus_murder_rate <- murders %>% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555"
  },
  {
    "objectID": "series/R Basic/about.html#summarizing-with-more-than-one-value",
    "href": "series/R Basic/about.html#summarizing-with-more-than-one-value",
    "title": "R Basic",
    "section": "\n3.7 Summarizing with more than one value",
    "text": "3.7 Summarizing with more than one value\n\n3.7.1 Key Points\n\nThe quantile() function can be used to return the min, median, and max in a single line of code.\n\n3.7.2 Code\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region using quantile\n# note that this returns a vector\nmurders %>% \n  filter(region == \"West\") %>%\n  summarize(range = quantile(rate, c(0, 0.5, 1)))\n\n     range\n1 0.514592\n2 1.292453\n3 3.629527\n\n# returning minimum, median, and maximum as a data frame\nmy_quantile <- function(x){\n  r <-  quantile(x, c(0, 0.5, 1))\n  data.frame(minimum = r[1], median = r[2], maximum = r[3]) \n}\nmurders %>% \n  filter(region == \"West\") %>%\n  summarize(my_quantile(rate))\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527"
  },
  {
    "objectID": "series/R Basic/about.html#pull-to-access-to-columns",
    "href": "series/R Basic/about.html#pull-to-access-to-columns",
    "title": "R Basic",
    "section": "\n3.8 Pull to access to columns",
    "text": "3.8 Pull to access to columns\n\n3.8.1 Key Points\n\nThe pull() function can be used to access values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the pull() function.\n\n3.8.2 Code\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate <- murders %>% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# us_murder_rate is stored as a data frame\nclass(us_murder_rate)\n\n[1] \"data.frame\"\n\n# the pull function can return it as a numeric value\nus_murder_rate %>% pull(rate)\n\n[1] 3.034555\n\n# using pull to save the number directly\nus_murder_rate <- murders %>% \n  summarize(rate = sum(total) / sum(population) * 10^5) %>%\n  pull(rate)\nus_murder_rate\n\n[1] 3.034555\n\n# us_murder_rate is now stored as a number\nclass(us_murder_rate)\n\n[1] \"numeric\""
  },
  {
    "objectID": "series/R Basic/about.html#the-dot-placeholder",
    "href": "series/R Basic/about.html#the-dot-placeholder",
    "title": "R Basic",
    "section": "\n3.9 The dot placeholder",
    "text": "3.9 The dot placeholder\n\n3.9.1 Key Points\n\nThe dot (.) can be thought of as a placeholder for the data being passed through the pipe.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate <- murders %>% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# using the dot to access the rate\nus_murder_rate <- murders %>% \n  summarize(rate = sum(total) / sum(population) * 10^5) %>%\n  .$rate\nus_murder_rate\n\n[1] 3.034555\n\nclass(us_murder_rate)\n\n[1] \"numeric\""
  },
  {
    "objectID": "series/R Basic/about.html#group-then-summarize",
    "href": "series/R Basic/about.html#group-then-summarize",
    "title": "R Basic",
    "section": "\n3.10 Group then summarize",
    "text": "3.10 Group then summarize\n\n3.10.1 Key Points\n\nSplitting data into groups and then computing summaries for each group is a common operation in data exploration.\nWe can use the dplyr group_by() function to create a special grouped data frame to facilitate such summaries.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# group by region\nmurders %>% group_by(region)\n\n# A tibble: 51 × 6\n# Groups:   region [4]\n   state                abb   region    population total  rate\n   <chr>                <chr> <fct>          <dbl> <dbl> <dbl>\n 1 Alabama              AL    South        4779736   135  2.82\n 2 Alaska               AK    West          710231    19  2.68\n 3 Arizona              AZ    West         6392017   232  3.63\n 4 Arkansas             AR    South        2915918    93  3.19\n 5 California           CA    West        37253956  1257  3.37\n 6 Colorado             CO    West         5029196    65  1.29\n 7 Connecticut          CT    Northeast    3574097    97  2.71\n 8 Delaware             DE    South         897934    38  4.23\n 9 District of Columbia DC    South         601723    99 16.5 \n10 Florida              FL    South       19687653   669  3.40\n# … with 41 more rows\n\n# summarize after grouping\nmurders %>% \n  group_by(region) %>%\n  summarize(median = median(rate))\n\n# A tibble: 4 × 2\n  region        median\n  <fct>          <dbl>\n1 Northeast       1.80\n2 South           3.40\n3 North Central   1.97\n4 West            1.29"
  },
  {
    "objectID": "series/R Basic/about.html#sorting-data-tables",
    "href": "series/R Basic/about.html#sorting-data-tables",
    "title": "R Basic",
    "section": "\n3.11 Sorting data tables",
    "text": "3.11 Sorting data tables\n\n3.11.1 Key Points\n\nTo order an entire table, we can use the dplyr function arrange().\nWe can also use nested sorting to order by additional columns.\nThe function head() returns on the first few lines of a table.\nThe function top_n() returns the top n rows of a table.\n\n3.11.2 Code\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n\n# order the states by population size\nmurders %>% arrange(population) %>% head()\n\n                 state abb        region population total       rate\n1              Wyoming  WY          West     563626     5  0.8871131\n2 District of Columbia  DC         South     601723    99 16.4527532\n3              Vermont  VT     Northeast     625741     2  0.3196211\n4         North Dakota  ND North Central     672591     4  0.5947151\n5               Alaska  AK          West     710231    19  2.6751860\n6         South Dakota  SD North Central     814180     8  0.9825837\n\n# order the states by murder rate - the default is ascending order\nmurders %>% arrange(rate) %>% head()\n\n          state abb        region population total      rate\n1       Vermont  VT     Northeast     625741     2 0.3196211\n2 New Hampshire  NH     Northeast    1316470     5 0.3798036\n3        Hawaii  HI          West    1360301     7 0.5145920\n4  North Dakota  ND North Central     672591     4 0.5947151\n5          Iowa  IA North Central    3046355    21 0.6893484\n6         Idaho  ID          West    1567582    12 0.7655102\n\n# order the states by murder rate in descending order\nmurders %>% arrange(desc(rate)) %>% head()\n\n                 state abb        region population total      rate\n1 District of Columbia  DC         South     601723    99 16.452753\n2            Louisiana  LA         South    4533372   351  7.742581\n3             Missouri  MO North Central    5988927   321  5.359892\n4             Maryland  MD         South    5773552   293  5.074866\n5       South Carolina  SC         South    4625364   207  4.475323\n6             Delaware  DE         South     897934    38  4.231937\n\n# order the states by region and then by murder rate within region\nmurders %>% arrange(region, rate) %>% head()\n\n          state abb    region population total      rate\n1       Vermont  VT Northeast     625741     2 0.3196211\n2 New Hampshire  NH Northeast    1316470     5 0.3798036\n3         Maine  ME Northeast    1328361    11 0.8280881\n4  Rhode Island  RI Northeast    1052567    16 1.5200933\n5 Massachusetts  MA Northeast    6547629   118 1.8021791\n6      New York  NY Northeast   19378102   517 2.6679599\n\n# return the top 10 states by murder rate\nmurders %>% top_n(10, rate)\n\n                  state abb        region population total      rate\n1               Arizona  AZ          West    6392017   232  3.629527\n2              Delaware  DE         South     897934    38  4.231937\n3  District of Columbia  DC         South     601723    99 16.452753\n4               Georgia  GA         South    9920000   376  3.790323\n5             Louisiana  LA         South    4533372   351  7.742581\n6              Maryland  MD         South    5773552   293  5.074866\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9              Missouri  MO North Central    5988927   321  5.359892\n10       South Carolina  SC         South    4625364   207  4.475323\n\n# return the top 10 states ranked by murder rate, sorted by murder rate\nmurders %>% arrange(desc(rate)) %>% top_n(10)\n\nSelecting by rate\n\n\n                  state abb        region population total      rate\n1  District of Columbia  DC         South     601723    99 16.452753\n2             Louisiana  LA         South    4533372   351  7.742581\n3              Missouri  MO North Central    5988927   321  5.359892\n4              Maryland  MD         South    5773552   293  5.074866\n5        South Carolina  SC         South    4625364   207  4.475323\n6              Delaware  DE         South     897934    38  4.231937\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9               Georgia  GA         South    9920000   376  3.790323\n10              Arizona  AZ          West    6392017   232  3.629527"
  },
  {
    "objectID": "series/R Basic/about.html#introduction-to-data.table",
    "href": "series/R Basic/about.html#introduction-to-data.table",
    "title": "R Basic",
    "section": "\n3.12 Introduction to data.table",
    "text": "3.12 Introduction to data.table\n\n3.12.1 Key Points\n\nIn this course, we often use tidyverse packages to illustrate because these packages tend to have code that is very readable for beginners.\nThere are other approaches to wrangling and analyzing data in R that are faster and better at handling large objects, such as the data.table package.\nSelecting in data.table uses notation similar to that used with matrices.\nTo add a column in data.table, you can use the := function.\nBecause the data.table package is designed to avoid wasting memory, when you make a copy of a table, it does not create a new object. The := function changes by reference. If you want to make an actual copy, you need to use the copy() function.\nSide note: the R language has a new, built-in pipe operator as of version 4.1: |>. This works similarly to the pipe %>% you are already familiar with. You can read more about the |> pipe here External link.\n\n3.12.2 Code\n\n# install the data.table package before you use it!\ninstall.packages(\"data.table\")\n\n# load data.table package\nlibrary(data.table)\n\n# load other packages and datasets\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\n\n# convert the data frame into a data.table object\nmurders <- setDT(murders)\n\n# selecting in dplyr\nselect(murders, state, region)\n\n# selecting in data.table - 2 methods\nmurders[, c(\"state\", \"region\")] |> head()\nmurders[, .(state, region)] |> head()\n\n# adding or changing a column in dplyr\nmurders <- mutate(murders, rate = total / population * 10^5)\n\n# adding or changing a column in data.table\nmurders[, rate := total / population * 100000]\nhead(murders)\nmurders[, \":=\"(rate = total / population * 100000, rank = rank(population))]\n\n# y is referring to x and := changes by reference\nx <- data.table(a = 1)\ny <- x\n\nx[,a := 2]\ny\n\ny[,a := 1]\nx\n\n# use copy to make an actual copy\nx <- data.table(a = 1)\ny <- copy(x)\nx[,a := 2]\ny"
  },
  {
    "objectID": "series/R Basic/about.html#subsetting-with-data.table",
    "href": "series/R Basic/about.html#subsetting-with-data.table",
    "title": "R Basic",
    "section": "\n3.13 Subsetting with data.table",
    "text": "3.13 Subsetting with data.table\n\n3.13.1 Key Points\nSubsetting in data.table uses notation similar to that used with matrices.\n\n3.13.2 Code\n\n# load packages and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nlibrary(data.table)\nmurders <- setDT(murders)\nmurders <- mutate(murders, rate = total / population * 10^5)\nmurders[, rate := total / population * 100000]\n\n# subsetting in dplyr\nfilter(murders, rate <= 0.7)\n\n# subsetting in data.table\nmurders[rate <= 0.7]\n\n# combining filter and select in data.table\nmurders[rate <= 0.7, .(state, rate)]\n\n# combining filter and select in dplyr\nmurders %>% filter(rate <= 0.7) %>% select(state, rate)"
  },
  {
    "objectID": "series/R Basic/about.html#summarizing-with-data.table",
    "href": "series/R Basic/about.html#summarizing-with-data.table",
    "title": "R Basic",
    "section": "\n3.14 Summarizing with data.table",
    "text": "3.14 Summarizing with data.table\n\n3.14.1 Key Points\n\nIn data.table we can call functions inside .()and they will be applied to rows.\nThe group_by followed by summarize in dplyr is performed in one line in data.table using the by argument.\n\n3.14.2 Code\n\n# load packages and prepare the data - heights dataset\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(heights)\nheights <- setDT(heights)\n\n# summarizing in dplyr\ns <- heights %>% \n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# summarizing in data.table\ns <- heights[, .(average = mean(height), standard_deviation = sd(height))]\n\n# subsetting and then summarizing in dplyr\ns <- heights %>% \n  filter(sex == \"Female\") %>%\n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# subsetting and then summarizing in data.table\ns <- heights[sex == \"Female\", .(average = mean(height), standard_deviation = sd(height))]\n\n# previously defined function\nmedian_min_max <- function(x){\n  qs <- quantile(x, c(0.5, 0, 1))\n  data.frame(median = qs[1], minimum = qs[2], maximum = qs[3])\n}\n\n# multiple summaries in data.table\nheights[, .(median_min_max(height))]\n\n# grouping then summarizing in data.table\nheights[, .(average = mean(height), standard_deviation = sd(height)), by = sex]"
  },
  {
    "objectID": "series/R Basic/about.html#sorting-data-frames",
    "href": "series/R Basic/about.html#sorting-data-frames",
    "title": "R Basic",
    "section": "\n3.15 Sorting data frames\n",
    "text": "3.15 Sorting data frames\n\n\n3.15.1 Key Points\n\nTo order rows in a data frame using data.table, we can use the same approach we used for filtering.\nThe default sort is an ascending order, but we can also sort tables in descending order.\nWe can also perform nested sorting by including multiple variables in the desired sort order.\n\n3.15.2 Code\n\n# load packages and datasets and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(dslabs)\ndata(murders)\nmurders <- setDT(murders)\nmurders[, rate := total / population * 100000]\n\n# order by population\nmurders[order(population)] |> head()\n\n# order by population in descending order\nmurders[order(population, decreasing = TRUE)] \n\n# order by region and then murder rate\nmurders[order(region, rate)]"
  },
  {
    "objectID": "series/R Basic/about.html#programming-basics-1",
    "href": "series/R Basic/about.html#programming-basics-1",
    "title": "R Basic",
    "section": "\n4.1 Programming Basics",
    "text": "4.1 Programming Basics\nIntroduction to Programming in R"
  },
  {
    "objectID": "series/R Basic/about.html#basic-condationals",
    "href": "series/R Basic/about.html#basic-condationals",
    "title": "R Basic",
    "section": "\n4.2 Basic Condationals",
    "text": "4.2 Basic Condationals\n\n4.2.1 Key Points\n\nThe most common conditional expression in programming is an if-else statement, which has the form “if [condition], perform [expression], else perform [alternative expression]”.\nThe ifelse() function works similarly to an if-else statement, but it is particularly useful since it works on vectors by examining each element of the vector and returning a corresponding answer accordingly.\nThe any() function takes a vector of logicals and returns true if any of the entries are true.\nThe all() function takes a vector of logicals and returns true if all of the entries are true.\n\n4.2.2 Code\n\n# an example showing the general structure of an if-else statement\na <- 0\nif(a!=0){\n  print(1/a)\n} else{\n  print(\"No reciprocal for 0.\")\n}\n\n# an example that tells us which states, if any, have a murder rate less than 0.5\nlibrary(dslabs)\ndata(murders)\nmurder_rate <- murders$total / murders$population*100000\nind <- which.min(murder_rate)\nif(murder_rate[ind] < 0.5){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has murder rate that low\")\n}\n\n# changing the condition to < 0.25 changes the result\nif(murder_rate[ind] < 0.25){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has a murder rate that low.\")\n}\n\n# the ifelse() function works similarly to an if-else conditional\na <- 0\nifelse(a > 0, 1/a, NA)\n\n# the ifelse() function is particularly useful on vectors\na <- c(0,1,2,-4,5)\nresult <- ifelse(a > 0, 1/a, NA)\n\n# the ifelse() function is also helpful for replacing missing values\ndata(na_example)\nno_nas <- ifelse(is.na(na_example), 0, na_example) \nsum(is.na(no_nas))\n\n# the any() and all() functions evaluate logical vectors\nz <- c(TRUE, TRUE, FALSE)\nany(z)\nall(z)"
  },
  {
    "objectID": "series/R Basic/about.html#functions",
    "href": "series/R Basic/about.html#functions",
    "title": "R Basic",
    "section": "\n4.3 Functions",
    "text": "4.3 Functions\n\n4.3.1 Key Points\n\nThe R function called function() tells R you are about to define a new function.\nFunctions are objects, so must be assigned a variable name with the arrow operator.\n\nThe general way to define functions is:\n\n\ndecide the function name, which will be an object,\n\n\ntype function() with your function’s arguments in parentheses, - (3) write all the operations inside brackets.\n\n\n\nVariables defined inside a function are not saved in the workspace.\n\n4.3.2 Code\n\n# example of defining a function to compute the average of a vector x\navg <- function(x){\n  s <- sum(x)\n  n <- length(x)\n  s/n\n}\n\n# we see that the above function and the pre-built R mean() function are identical\nx <- 1:100\nidentical(mean(x), avg(x))\n\n# variables inside a function are not defined in the workspace\ns <- 3\navg(1:10)\ns\n\n# the general form of a function\nmy_function <- function(VARIABLE_NAME){\n  perform operations on VARIABLE_NAME and calculate VALUE\n  VALUE\n}\n\n# functions can have multiple arguments as well as default values\navg <- function(x, arithmetic = TRUE){\n  n <- length(x)\n  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))\n}"
  },
  {
    "objectID": "series/R Basic/about.html#for-loops",
    "href": "series/R Basic/about.html#for-loops",
    "title": "R Basic",
    "section": "\n4.4 For Loops",
    "text": "4.4 For Loops\n\n4.4.1 Key Points\n\nFor-loops perform the same task over and over while changing the variable. They let us define the range that our variable takes, and then changes the value with each loop and evaluates the expression every time inside the loop.\nThe general form of a for-loop is: “For i in [some range], do operations”. This i changes across the range of values and the operations assume i is a value you’re interested in computing on.\nAt the end of the loop, the value of i is the last value of the range.\n\n4.4.2 Code\n\n# creating a function that computes the sum of integers 1 through n\ncompute_s_n <- function(n){\n  x <- 1:n\n  sum(x)\n}\n\n# a very simple for-loop\nfor(i in 1:5){\n  print(i)\n}\n\n# a for-loop for our summation\nm <- 25\ns_n <- vector(length = m) # create an empty vector\nfor(n in 1:m){\n  s_n[n] <- compute_s_n(n)\n}\n\n# creating a plot for our summation function\nn <- 1:m\nplot(n, s_n)\n\n# a table of values comparing our function to the summation formula\nhead(data.frame(s_n = s_n, formula = n*(n+1)/2))\n\n# overlaying our function with the summation formula\nplot(n, s_n)\nlines(n, n*(n+1)/2)"
  },
  {
    "objectID": "series/Data Visualization/about.html",
    "href": "series/Data Visualization/about.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data. Additionally, it provides an excellent way for employees or business owners to present data to non-technical audiences without confusion.\nIn the world of Big Data, data visualization tools and technologies are essential to analyze massive amounts of information and make data-driven decisions."
  },
  {
    "objectID": "series/Data Visualization/about.html#overview",
    "href": "series/Data Visualization/about.html#overview",
    "title": "Data Visualization",
    "section": "\n2.1 Overview",
    "text": "2.1 Overview\nAfter completing this section, we will:\n\nunderstand the importance of data visualization for communicating data-driven findings.\nbe able to use distributions to summarize data.\nbe able to use the average and the standard deviation to understand the normal distribution\nbe able to access how well a normal distribution fit the data using a quantile-quantile plot.\nbe able to interpret data from a box plot"
  },
  {
    "objectID": "series/Data Visualization/about.html#introduction-to-data-visualization",
    "href": "series/Data Visualization/about.html#introduction-to-data-visualization",
    "title": "Data Visualization",
    "section": "\n2.2 Introduction to Data Visualization",
    "text": "2.2 Introduction to Data Visualization\n\n2.2.1 Key Point:\n\nPlots of data easily communicate information that is difficult to extract from table of raw values.\nData visualization is a key component of exploratory data analysis (EDA), in which the properties of data are explored through visualization and summarization techniques.\nData visualization can help discover biases, systematic errors, mistakes and other unexpected problems in data before those data are incorporated into potentially flawed analysis.\nBasics of data visualization and EDA will be covered in R by using the ggplot2 package and motivating examples from world health, economics and infections disease.\n\n2.2.2 Code:\n\nlibrary(dslabs)\ndata(murders)\nhead(murders)\n\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65"
  },
  {
    "objectID": "series/Data Visualization/about.html#introduction-to-distributions",
    "href": "series/Data Visualization/about.html#introduction-to-distributions",
    "title": "Data Visualization",
    "section": "\n2.3 Introduction to Distributions",
    "text": "2.3 Introduction to Distributions\n\n2.3.1 Key Points:\n(Variance/Deviation Var)方差: 方差越大，数据的波动越大；方差越小，数据的波动就越小。\n(Standard Deviation)标准差: 方差开根号。\n\nThe most basic statistical summary of a list of object is its distribution.\nWe will learn ways to visualize and analyze distributions in the upcoming videos.\nIn some cases, data can be summarized by two-number summary: the average and standard deviation.I will learn to use data visualization to determine when that is appropriate.\n\n2.3.2 Data Types\nIn R, there are 6 basic data types:\n\nlogical\nnumeric\ninteger\ncomplex\ncharacter\nraw\n\n\n\n\n\n\n\nImportant\n\n\n\nCategorical data are variables that are defined by a small number of groups.\n\nOrdinal categorical data have an inherent order to the categories (mild/medium/hot, for example).\nNon-ordinal categorical data have no order to the categories.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNumerical data take a variety of numeric values.\n\nContinuous variables can take any value.\nDiscrete variables are limited to sets of specific values.\n\n\n\n\n\n\n\n\nflowchart LR\n  A[Main variable types] --> B{Catrgorical}\n  A[Main variable types] --> C{Numeric}\n  B{Catrgorical} --> D[ordinal]\n  B{Catrgorical} --> E[non-ordinal]\n  C{Numeric} --> F[continuous]\n  C{Numeric} --> G[discrete]\n\n\n\n\n\n\n\n\n\n2.3.3 Exercise\n\n# extract the variable names from a dataset\nnames(x)\n# explore how many unique values are used in dataset\nunique(x)\n# determine how many variable were reported\nlength(x)\n# determine how many unique variable were reported\nlength(unique(x))\n# to compute the frequencies of each unique value\ntable(x)"
  },
  {
    "objectID": "series/Data Visualization/about.html#describe-heights-to-et",
    "href": "series/Data Visualization/about.html#describe-heights-to-et",
    "title": "Data Visualization",
    "section": "\n2.4 Describe Heights to ET",
    "text": "2.4 Describe Heights to ET\n\n2.4.1 key point:\n\nA distribution is a function or description that shows the possible values of a variable and how often those values occur.\nFor categorical variables, the distribution describes the proportions of each category.\nA frequency table is the simplest way to show a categorical distribution. Use prop.table() to convert a table of counts to a frequency table. Barplots display the distribution of categorical variables and are a way to visualize the information in frequency tables.\nFor continuous numerical data, reporting the frequency of each unique entry is not an effective summary as many or most values are unique. Instead, a distribution function is required.\nThe cumulative distribution function (CDF) is a function that reports the proportion of data below a value a for all values of a :F(a)=Pr(x≤a).\nThe proportion of observations between any two values a and b can be computed from the CDF as F(b)-F(a).\nA histogram divides data into non-overlapping bins of the same size and plots the counts of number of values that fall in that interval.\n\n2.4.2 Code:\nR 语言学习 - table() 结果提取.\n\n# load the dataset\nlibrary(dslabs)\ndata(heights)\n# make a table of category proportions\nprop.table(table(heights$sex))"
  },
  {
    "objectID": "series/Data Visualization/about.html#cumulative-distribution-function",
    "href": "series/Data Visualization/about.html#cumulative-distribution-function",
    "title": "Data Visualization",
    "section": "\n2.5 Cumulative Distribution Function",
    "text": "2.5 Cumulative Distribution Function\nEvery continuous distribution has cumulative distribution function (CDF). The CDF defines the proportion of the data below a given value for all values of a :\n\nCumulative Distribution Function (CDF)\n\n\n\nAs defined above, this plot of the CDF for male heights has height value a on the x-axis and the proportion of student with heights of that value or lower(F(a)) on the y-axis.\nThe CDF is essential for calculating probabilities related to continuous data. In a continuous dataset, the probability of a specific exact value is not informative because most entries are unique. For example, in the student heights data, only one individual reported a height of 68.8976377952726 inches, but many students rounded similar heights to 69 inches. If we computed exact value probabilities, we would find that being exactly 69 inches is much more likely than being a non-integer exact height, which does not match our understanding that height is continuous. We can instead use the CDF to obtain a useful summary, such as the probability that a student is between 68.5 and 69.5 inches.\nFor datasets that are not normal, the CDF can be calculated manually by defining a function to compute the probability above. This function can then be applied to a range of values across the range of the dataset to calculate a CDF. Given a datasetmy_data, the CDF can be calculated and plotted like this:\nR语言中的[apply()]，[lapply()]，[sapply()]，tapply()函数以及示例\n\n2.5.1 Code for CDF:\n\n# Cumulative Distribution Function \na <- seq(min(x), max(x), length) # define range of the values\ncdf_function <- function(x) {\n    mean(my_data <= x)\n}\ncdf_values <- sapply(a, cdf_function)\nplot(a, cdf_values)\n\n\n2.5.2 Code for student height:\n\n# example for student heights\na <- seq(min(heights$height), max(heights$height), length = 100)\ncdf_function <- function(x){\n  mean(heights$height <= x)\n}\ncdf_value <- sapply(a, cdf_function)\nplot(a, cdf_value)\n\n\n\n\nThe CDF defines that proportion of data below a cut-off a. To define the proportion of values above a, we compute: 1-F(a)\nTo define the proportion of values between a and b, we compute: F(b)-F(a)\nNote that the CDF can help compute probabilities. The probability of observing a randomly chosen value between a and b is equal to the proportion of values between a and b, which we compute with the CDF."
  },
  {
    "objectID": "series/Data Visualization/about.html#smooth-density-plots",
    "href": "series/Data Visualization/about.html#smooth-density-plots",
    "title": "Data Visualization",
    "section": "\n2.6 Smooth Density Plots",
    "text": "2.6 Smooth Density Plots\n\n2.6.1 Key Point:\n\n\n\n\n\n\nA further note on histograms\n\n\n\nThe choice of binwidth has a determinative effect on sharp. There is no “correct” choice for binwidth, and you can sometimes gain insights into the data by experimenting with binwidths.\n\n\n\nSmooth density plots can be thought of as histograms where the binwidth is extremely or infinitely small. The smoothing function makes estimates of the true continuous trend of the data given the available sample of data points.\nThe degree of smoothness can be controlled by an argument in the plotting function.\nWhile the histogram is an assumption-free summary, the smooth density plot is shaped by assumptions and choices you make as a data analyst.\nThe y-axis is scaled so that the area under the density curve sums to 1. This means that interpreting value on the y-axis is not straightforward. To determine the proportion of data in between two values, compute the area under the smooth density curve in the region between those values.\nAn advantage of smooth densities over histograms is that densities are easier to compare visually."
  },
  {
    "objectID": "series/Data Visualization/about.html#normal-distribution",
    "href": "series/Data Visualization/about.html#normal-distribution",
    "title": "Data Visualization",
    "section": "\n2.7 Normal Distribution",
    "text": "2.7 Normal Distribution\n\n2.7.1 Key Points:\n\n\nThe normal distribution:\n\nis centered around one value, the mean\n\nis symmetric(对称) around the mean.\nis defined completely by its mean(\\mu) and standard deviation(\\sigma)\n\n\nAlways has the same proportion of observations within a given distance of the mean (for example, 95% with 2\\sigma)\n\n\nThe standard deviation is the average distance between a value and the mean value.\nCalculate the mean using the mean() function.\nCalculate the standard deviation using the sd() function or manually.\n\nStandard units describe how many standard deviations a value is away from the mean. The z-score, or number of standard deviation an observation is away from the mean \\mu:\n\n  z = (x-\\mu)/\\sigma\n  \n\nComputer standard units with the scale() function.\nImportant: to calculate the proportion of value that meet a certain condition, use the mean function on a logical vector. Because TRUE is converted to 1 and FALSE is converted to 0, taking the mean of this vector yields the proportion of TURE."
  },
  {
    "objectID": "series/Data Visualization/about.html#equation-for-the-normal-distribution",
    "href": "series/Data Visualization/about.html#equation-for-the-normal-distribution",
    "title": "Data Visualization",
    "section": "\n2.8 Equation for the normal distribution",
    "text": "2.8 Equation for the normal distribution\nThe normal distribution is mathematically defined by the following formula for any mean \\mu and standard deviation \\sigma:\n\nPr(a < x < b) = \\int_{a}^b\\frac{1}{\\sqrt{2\\pi\\mu}}{e}^{-\\frac{1}{2}(\\frac{x-\\mu^2}{\\sigma})}dx\n\nWhen standard unites z=0, the normal distribution is at a maximum, the mean \\mu. The function is defined to be symmetric around z=0.\nThe normal distribution of z-score is called the standard normal distribution and is defined by \\mu=0 and \\sigma=1.\nZ-score are useful to quickly evalute whether an observation is average or extreme. Z-scores near 0 are average. Z-score above 2 or below -2 are significantly above or blew the mean, and z-scores above 3 or below -3 are extrmely rate.\n\n2.8.1 Code:\n\n# define x as vector of male heights\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\nindex <- heights$sex==\"Male\"\nx <- heights$height[index]\n\n# calculate the mean and standard deviation manually\naverage <- sum(x)/length(x)\nSD <- sqrt(sum((x-average)^2)/length(x))\n\n# built-in mean and sd functions - note that the audio and printed value disagree\naverage <- mean(x)\nSD <- sd(x)\nc(average = average, SD = SD)\n\n# calculate standard units\nz <- scale(x)\n\n# calculate proportion of value within 2 SD of mean\nmean(abs(z) < 2)\n\nfunction sd():The built-in R function sd() calculates the standard deviation, but it divides by length(x)-1 instead of length(x). When the length of the list is large, this difference is negligible and you can use the built-in sd() function. Otherwise, you should compute σ by hand. For this course series, assume that you should use the sd() function unless you are told not to do so.\nHere we will learn more about benchmark z-score value and their corresponding probabilities.\n\n2.8.2 The 68-95-99.7 Rule\nThe normal distribution is associated with the 68-95-99.7 rule. This rule describes the probability of observing events within a ceration number of standard deviations of the mean.\n\nNormal Distribution Probabilities\n\n\n\nThe probability distribution function for the normal distribution is defined such that:\n\nAbout 68% of observations will be within one standard deviation of the mean(\\mu\\pm\\sigma). In standard units, this is equivalent to a z-score of |z|\\leq2\n\n\n\nProbability of an observation within 1 SD of mean\n\n\n\n\nAbout 95% of observations will be within two standard seviations of the mean(\\mu\\pm2\\sigma). In standard units, this is equivalent to a z-sore of |z|\\leq2.\n\n\nProbability of an ovservation within 2 SD of mean\n\n\n\n\nAbout 99.7% of observations will be within three standard deviations of the mean(\\mu\\pm3\\sigma). In standard units, this is equivalent to a z-score of |z|\\leq3.\n\n\nProbability of an observation within 3 SD of mean"
  },
  {
    "objectID": "series/Data Visualization/about.html#the-normal-cdf-and-pnorm",
    "href": "series/Data Visualization/about.html#the-normal-cdf-and-pnorm",
    "title": "Data Visualization",
    "section": "\n2.9 The Normal CDF and pnorm",
    "text": "2.9 The Normal CDF and pnorm\n\n2.9.1 Key points:\n\nThe normal distribution has a mathematically defined CDF which can be computed in R with the function pnorm.\npnom(a, avg, s) gives the value of the cumculative distribution function F(a) for the normal distribution defined by average avg and standard deviation s.\nwe say that a random quantity is normally distributed with average avg and standard deviation s if the approximate pnorm(a, avg, s) holds for all values of a.\nIf we are willing to use the normal approximation for height, we can estimate the distribution simply from the mean and standard deviation of our values.\nIf we treat the height data as discrete rather than categorical, we see that the data are not very useful because integer values are more common that expected due to rounding. This is called discretization.\nWith rounded data, the normal approximation is particularly useful when computing probabilities of intervals of length 1 that include exactly over integer.\n\n2.9.2 Code: Using pnorm to calculate probabilities\nGiven male heights x:\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(\"heights\")\nx <- heights %>% filter(sex==\"Male\") %>% pull(height)\n\nwe can estimate the probability that a male is taller than 70.5 inches with:\n\n1 - pnorm(70.5, mean(x), sd(x))\n\n\n2.9.3 Code: Discretization and the normal approximation\n\n# plot distribution of exact heights in data\nplot(prop.table(table(x)), xlab = \"a = Height in inches\", ylab = \"Pr(x = a)\")\n\n\n\n\n\n# probabilities in actual data over length 1 ranges containing a integer\nmean(x <= 68.5) - mean(x <= 67.5)\nmean(x <= 69.5) - mean(x <= 68.5)\nmean(x <= 70.5) - mean(x <= 69.5)\n\n# probabilities in normal approximation match well\npnorm(68.5, mean(x), sd(x)) - pnorm(67.5, mean(x), sd(x))\npnorm(69.5, mean(x), sd(x)) - pnorm(68.5, mean(x), sd(x))\npnorm(70.5, mean(x), sd(x)) - pnorm(69.5, mean(x), sd(x))\n\n# probabilities in actual data over other ranges don't match normal approx as well\nmean(x <= 70.9) - mean(x <= 70.1)\npnorm(70.9, mean(x), sd(x)) - pnorm(70.1, mean(x), sd(x))"
  },
  {
    "objectID": "series/Data Visualization/about.html#definition-of-quantiles",
    "href": "series/Data Visualization/about.html#definition-of-quantiles",
    "title": "Data Visualization",
    "section": "\n2.10 Definition of quantiles",
    "text": "2.10 Definition of quantiles\n\n2.10.1 Definition of quantiles\nQuantiles are cut off points that divide a dataset into intervals with set probability. The qth quantile is the value at which q% of the observation are equal to or less than that value.\n\n2.10.2 Using the quantile function\nGiven a dataset data and desired quantile q, you can find the q the quantile of data with:\n\nquantile(data,q)\n\n\n2.10.3 Percentiles\nPercentiles are the quantiles that divide a dataset into 100 intervals each with 1% probability. You can determine all percentiles of a dataset data like this:\n\np <- seq(0.01, 0.09, 0.01)\nquantile(data, p)\n\n\n2.10.4 Quartiles\nQuartiles divide a dataset into 4 parts each with 25% probability. They are equal to the 25th, 50th and 75th percentiles. The 25th percentile is also known as the 1st quartile, the 50th percentile is also konwn as the median, and the 75th percentile is also knowns as the 3rd quartile.\nThe summary() function returns the minimum, quartiles and maximum of a vector.\n\n2.10.5 Examples\nLoad the heights dataset from the dslabs package:\n\nlibrary(dslabs)\ndata(\"heights\")\n\nUsesummaryon the heights$height variable to find the quartiles:\n\nsummary(heights$height)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  50.00   66.00   68.50   68.32   71.00   82.68 \n\n\nFind the percentiles of height$height:\n\np <- seq(0.01, 0.99, 0.01)\npercentiles <- quantile(heights$height, p)\n\nConfirm that the 25th and 75th percentiles match that 1st and 3rd quartiles. Note that quantile() returns a named vector. You can access the 25th and 75th percentiles like this (adapt the code for other percentile value):\n\npercentiles[names(percentiles) == \"25%\"]\n\n25% \n 66 \n\npercentiles[names(percentiles) == \"75%\"]\n\n75% \n 71"
  },
  {
    "objectID": "series/Data Visualization/about.html#finding-quantile-with-qnorm",
    "href": "series/Data Visualization/about.html#finding-quantile-with-qnorm",
    "title": "Data Visualization",
    "section": "\n2.11 Finding quantile with qnorm",
    "text": "2.11 Finding quantile with qnorm\n\n2.11.1 Definiton of qnorm\n简单来说,qnorm是正态分布累积分布函数(CDF)的反函数， 也就是说它可以视为pnorm的反函数, 这里q指的是quantile, 即分位数\nThe qnorm() function gives the theoretical value of a quantile with probability p of observing a value equal to or less than that quantile value a normal distribution with mean mu and standard deviation sigma:\n\nqnorm(p, mu, sigma)\n\nBy default, mu=0 and sigma=1. Therefore, calling qnorm() with no arguments gives quantiles for the standard normal distribution.\n\nqnorm(p)\n\nRecall that quantiles are defined such that p is the probability of a random observation less than or equal to the quantile.\n\n2.11.2 Realation to pnorm\nThe pnorm() function gives the probability that a value from a standard normal distribution will be less than or equal to a z-score value z. consider: pnorm(-1.96)\\approx0.025 The result of pnorm() is the quantile. Note that: qnorm(0.025)\\approx-1.96 qnorm() and pnorm are inverse functions: pnorm(qnorm(0.025))\\equiv0.025\n\n2.11.3 Theoretical quantiles\nYou can use qnorm() to determine the theoretical quantiles of a dataset: that is, the theoretical value of quantiles assuming that a dataset follows a normal distribution. Run the qnorm() function with the desired probabilities p, mean mu and standard deviation sigma.\nSuppose male heights follow a normal distribution with a mean of 69 inches and standard deviation of 3 inches. The theoretical quantiles are:\n\np <- seq(0.01, 0.99, 0.01)\ntheoretical_quantiles <- qnorm(p, 69, 3)\n\nTheoretical quantiles can be compared to sample quantiles determined with the quantile function in order to evaluate whether the sample follows a normal distribution."
  },
  {
    "objectID": "series/Data Visualization/about.html#quantile-quantile-plots",
    "href": "series/Data Visualization/about.html#quantile-quantile-plots",
    "title": "Data Visualization",
    "section": "\n2.12 Quantile-Quantile Plots",
    "text": "2.12 Quantile-Quantile Plots\n\n2.12.1 Key Points:\n\nQuantile-quantile plots, or QQ-plot, are used to check whether distributions are well-approximated by a normal distribution.\nGiven a proportion p, the quantile q is the value such that the proportion of values in the data blew q is p.\nIn a QQ-plot, the sample quantiles in the observed data are compared to the theoretical quantiles expected from the normal distribution. If the data are well-approximated by the normal distribution, then the points on the QQ-plot will fall near the identity line(sample = theoretical).\nCalculate sample quantiles (observed quantiles) using the quantile() function.\nCalculate theoretical quantiles with the qnorm() function. qnorm() will caculate quantiles for the standard normal distribution (\\mu=0, \\sigma=1) by default, but it can calculate quantiles for any normal distribution given mean() and sd() arguments.\n\n2.12.2 Code:\n\n# define x and z\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\n\nindex <- heights$sex==\"Male\"\nx <- heights$height[index]\nz <- scale(x)\n\n# proportion of data below 69.5\nmean(x <= 69.5)\n\n[1] 0.5147783\n\n# calculate observed and theoretical quantiles\np <- seq(0.05, 0.95, 0.05)\nobserved_quantiles <- quantile(x, p)\ntheoretical_quantiles <- qnorm(p, mean = mean(x), sd = sd(x))\n\n# make QQ-plot\nplot(theoretical_quantiles, observed_quantiles)\nabline(0,1)\n\n\n\n# make QQ-plot with scaled values\nobserved_quantiles <- quantile(z, p)\ntheoretical_quantiles <- qnorm(p)\nplot(theoretical_quantiles, observed_quantiles)\nabline(0,1)"
  },
  {
    "objectID": "series/Data Visualization/about.html#percentiles-1",
    "href": "series/Data Visualization/about.html#percentiles-1",
    "title": "Data Visualization",
    "section": "\n2.13 Percentiles",
    "text": "2.13 Percentiles\n\n2.13.1 Key Points:\n\nPercentiles are the quantiles obtained when defining p as 0.01, 0.02,…,0.99. They summarize the values at which a certain percent of the observations are equal to or less than that value.\nThe 50th percentile is also known as the median.\nThe quartiles are the 25th, 50th and 75th percentiles."
  },
  {
    "objectID": "series/Data Visualization/about.html#boxplots",
    "href": "series/Data Visualization/about.html#boxplots",
    "title": "Data Visualization",
    "section": "\n2.14 Boxplots",
    "text": "2.14 Boxplots\nR语言如何绘制箱线图\n\n2.14.1 Key Points:\n\nWhen data do not follow a normal distribution and cannot be succinctly summarized by only the mean and standard deviation, an alternative is to report a five-number summary: range (ignoring outliers) and the quartiles (25th, 50th, 75th percentile).\nIn a boxplot, the box is defined by the 25th and 75th percentiles and the median is a horizontal line through the box. The whiskers show the range excluding outliers, and outliers are plotted separately as individual points.\nThe interquartile range is the distance between the 25th and 75th percentiles.\nBoxplots are particularly useful when comparing multiple distributions."
  },
  {
    "objectID": "series/Data Visualization/about.html#distribution-of-female-heights",
    "href": "series/Data Visualization/about.html#distribution-of-female-heights",
    "title": "Data Visualization",
    "section": "\n2.15 Distribution of Female Heights",
    "text": "2.15 Distribution of Female Heights\n\n2.15.1 Key Points:\n\nIf a distribution is not normal, it cannot be summarized with only the mean and standard seviation. Provide a histogram, smooth density or boxplot instead.\nA plot can force us to see unexpected results that make us question the quality or implication of our data."
  },
  {
    "objectID": "series/Data Visualization/about.html#overview-1",
    "href": "series/Data Visualization/about.html#overview-1",
    "title": "Data Visualization",
    "section": "\n3.1 Overview",
    "text": "3.1 Overview\nAfter completing ggplot2, we will:\n\nbe able to use ggplot2 to create data visualizations in R.\nbe able to explain what the data component of a graph is.\nbe able to identify the geometry component of a graph and know when to use which type of geometry. be able to explain what the aesthetic mapping component of a graph is.\nbe able to understand the scale component of a graph and select an appropriate scale component to use."
  },
  {
    "objectID": "series/Data Visualization/about.html#ggplot",
    "href": "series/Data Visualization/about.html#ggplot",
    "title": "Data Visualization",
    "section": "\n3.2 ggplot",
    "text": "3.2 ggplot\n\n3.2.1 ggplot2\n\nData visualization with ggolot2\nData visualization with ggplot2: Cheat Sheet\nThe R graph gallery example\n\n3.2.2 key Points:\n\nThroughout the series, we will create plots with the ggplot2 package. ggplot2 is part of the tidyverse suite of package, which you can load with library(tidyverse).\nNote that you can also load ggplot2 alone using the command library(ggplot2), instead of loading the entire tidyverse.\nggplot2 uses a grammar of graphics to break plots into building blocks that have intuitive syntax, making it easy to create relatively complex and aesthetically pleasing plots with relatively simple and readable code.\nggplot2 is designed to work excusively with tidy data (rows are observations and columns are variables)."
  },
  {
    "objectID": "series/Data Visualization/about.html#graph-components",
    "href": "series/Data Visualization/about.html#graph-components",
    "title": "Data Visualization",
    "section": "\n3.3 Graph Components",
    "text": "3.3 Graph Components\n\n3.3.1 Key Points:\n\nPlots in ggplot2 consist of 3 main components:\n\n\nData: The dataset being summarized\n\nGeometry: The type of plot(scatterplot, boxplot, barplot, histogram, qqplot, smooth desity, etc.)\n\nAesthetic mapping: Variable mapped to visual cues, such as x-axis and y-axis values and color.\n\n\n\n3.3.2 Code:\n\nlibrary(dslabs)\ndata(murders)"
  },
  {
    "objectID": "series/Data Visualization/about.html#creating-a-new-plot",
    "href": "series/Data Visualization/about.html#creating-a-new-plot",
    "title": "Data Visualization",
    "section": "\n3.4 Creating a New Plot",
    "text": "3.4 Creating a New Plot\n\n3.4.1 Key Points:\n\n\nYou can associated a dataset x with a ggplot object with any of the 3 commands:\n\nggplot(data = x)\nggplot(x)\nx %>% ggplot()\n\n\nYou can assign a ggplot object to a variable. If the object is not assigned to a variable, it will automatically be displayed.\nYou can display a ggplot object assigned to a variable by printing that variable.\n\nCode:\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\nggplot(data = murders)\n\nmurders %>% ggplot()\n\np <- ggplot(data = murders)\n\nclass(p)\n\nprint(p) # this is equivalent to simply typing p\np"
  },
  {
    "objectID": "series/Data Visualization/about.html#layers",
    "href": "series/Data Visualization/about.html#layers",
    "title": "Data Visualization",
    "section": "\n3.5 Layers",
    "text": "3.5 Layers\n\n3.5.1 Key Points:\n\nIn ggplot2, graphs are created by adding layers to the ggplot object: DATA %>% ggplot() + LAYER_1 + LAYER_2 + … + LAYER_N\nThe geometry layer defines that plot type and takes the format geom_x where x is the plot type.\nAesthetic mappings describe how properties of the data connect with features of the graph (axis position, color, size, etc.) define aesthetic mapping with aes() function.\naes() uses variable names from the object component (for example, total rather than murders$total).\ngeom_point() creates a scatterplot and requires x and y aesthetic mappings.\ngeom_text() and geom_label add text to a scatterplot and require x, y, and label aesthetic mappings.\nTo determine which aesthetic mappings are required for a geometry, read the help file for that geometry.\nYou can add layers with different aesthetic mappings to the same graph.\n\nCode: Adding layers to a plot\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\nmurders %>% ggplot() +\n  geom_point(aes(x = population/10^6, y = total))\n\n\n# add points layer to predefined ggplot object\np <- ggplot(data = murders)\np + geom_point(aes(population/10^6, total))\n\n\n\n# add text layer to scatterplot\np + geom_point(aes(population/10^6, total)) +\n  geom_text(aes(population/10^6, total, label = abb))\n\n\n\n\nCode: Example of aes behavior\n\n# no error from this call\np_test <- p + geom_text(aes(population/10^6, total, lable = abb))\n\n# error - \"abb\" is not a globally defined variable and cannot be found outside of aes\np_test <- p + geom_text(aes(population/10^6, total), label = abb)"
  },
  {
    "objectID": "series/Data Visualization/about.html#thinkering",
    "href": "series/Data Visualization/about.html#thinkering",
    "title": "Data Visualization",
    "section": "\n3.6 Thinkering",
    "text": "3.6 Thinkering\n\n3.6.1 Key Points:\n\nYou can modify arguments to geometry functions others than aes() and the data.\nThese arguments are not aesthetic mappings: the affect all data points the same way.\nGlobal aesthetic mappings apply to all geometries and can be defined when you initially call ggplot(). All the geometries added as layers will default to this mapping. Local aesthetic mapping add additional information or override the default mappings.\n\n\n\n\n\n\n\nNudge points a fixed distance\n\n\n\nposition_nudge(x = 0, y = 0) is generally useful for adjusting the position of items on discrete scales by a small amount. Nudging is built in to geom_text() because it’s so useful for moving labels a small distance from what they’re labeling.\n\n\nCode:\n\n# change the size of the points\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb))\n\n\n\n# move text labels slightly to the right\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb), nudge_x = 1)\n\n\n\n# simplify code by adding global aesthetic\np <- murders %>% ggplot(aes(population/10^6, total, label = abb))\np + geom_point(size = 3) +\n    geom_text(nudge_x = 1.5)\n\n\n\n# local aesthetics override global aesthetics\np + geom_point(size = 3) +\n  geom_text(aes(x = 10, y = 800, label = \"Hello there!\"))"
  },
  {
    "objectID": "series/Data Visualization/about.html#scales-labels-and-colors",
    "href": "series/Data Visualization/about.html#scales-labels-and-colors",
    "title": "Data Visualization",
    "section": "\n3.7 Scales, Labels, and Colors",
    "text": "3.7 Scales, Labels, and Colors\n\n3.7.1 Textbook links:\n\nTextbook section on scales\nTextbook section on labels and titles\nTextbook section on categories as colors\nTextbook section on annotation, shapes and adjustments\n\n3.7.2 Key Points:\n\nConvert the x-axis to log scale with scale_x_continuous(trans = \"log10\") or scale_x_log10(). Similar function exist for the y-axis.\nAdd axis title with xlab() and ylab() function. Add a plot title with the ggtitle() function.\nAdd a color mapping that colors points by a varaibale by defining col argument within aes(). To color all pints the same way, define col outside of aes().\nAdd a line with the geom_abline() geometry. geom_abline() takes arguments slop (default = 1) and intercept(default = 0). Change the color with col or color and line type with lty.\nPlacing the line layer after the point layer will overlay the the line on top of the points. To overlay points on the line, place the line layer before the point layer.\nThere are many additional ways to tweak your graph that can be found in the ggplot2 documentation, cheat sheet or on the internet. For example, you can change the legend title with scale_color_discrete.\n\n3.7.3 Code: Log-scale the x-axis and y-axis\n\n# define p\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\np <- murders %>% ggplot(aes(population/10^6, total, label = abb))\n\n# log base 10 scale the x-axis and y-axis\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_continuous(trans = \"log10\") +\n    scale_y_continuous(trans = \"log10\")\n\n\n# efficient log scaling of the axes\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10()\n\n\n\n\n\n3.7.4 Code: Add labels and title\n\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in million(log scale)\") +\n    ylab(\"Total number of murders(log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\")\n\n\n\n\n\n3.7.5 Code: Change color of the points\n\n# redefine p to be everything except the points layer\np <- murders %>% \n     ggplot(aes(population/10^6, total, label = abb)) +\n     geom_text(nudge_x = 0.075) +\n     scale_x_log10() +\n     scale_y_log10() +\n     xlab(\"Population in million(log scale)\") +\n     ylab(\"Total number of murders(log scale)\") +\n     ggtitle(\"US Gun Murders in 2010\")\n\n\n# make all points blue\np + geom_point(size = 3, color = \"blue\")\n\n\n\n\n\n# color points by region\np + geom_point(aes(col = region), size = 3)\n\n\n\n\n\n3.7.6 Code: Add a line with average murder rate\n\nr <- murders %>% \n     summarize(rate = sum(total) / sum(population) * 10^6) %>%      pull(rate)\n\np <- p + geom_point(aes(col = region), size = 3) +\n         geom_abline(intercept = log10(r)) # slop is default of 1\n\n# change line to dashed and dark grey, line under points\np + geom_abline(intercept = log(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3)\n\n\n\n\n\n\n\n\n\n\nLine types in R: Ity\n\n\n\nThe different line types available in R are shown in the figure hereafter. The argument lty can be used to specify the line type. To change line width, the argument lwd can be used.\n\n\n\n3.7.7 Code: Change legend title\n\n# capitalize legend title\np <- p + scale_color_discrete(name = \"Region\")\np"
  },
  {
    "objectID": "series/Data Visualization/about.html#add-on-packages",
    "href": "series/Data Visualization/about.html#add-on-packages",
    "title": "Data Visualization",
    "section": "\n3.8 Add-on packages",
    "text": "3.8 Add-on packages\n\n3.8.1 Textbook links:\n\nTextbook section on add-on packages\nTextbook section on putting it all together\n\n3.8.2 Key Points\n\nThe style of a ggplot graph can be changed using the theme() function.\nThe ggthemes package adds additional themes.\nThe ggrepel package includes a geometry that repels text labels, ensuring they do not overlap with each other: geom_text_repel().\n\n3.8.3 Code: Adding themes\n\n# theme used for graphs in the textbook and course\nlibrary(dslabs)\nds_theme_set()\n\n\n# themes from ggthemes\nlibrary(ggthemes)\n\n\np + theme_economist()    # style of the Economist magazine\n\n\n\np + theme_fivethirtyeight()    # style of the FiveThirtyEight website\n\n\n\n\n\n3.8.4 Code: Putting it all together to assemble the plot\n\n# load libraries\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(dslabs)\ndata(murders)\n\n\n# define the intercept\nr <- murders %>%\n    summarize(rate = sum(total) / sum(population) * 10^6) %>%\n    .$rate\n    \n# make the plot, combining all elements\nmurders %>%\n    ggplot(aes(population/10^6, total, label = abb)) +\n    geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3) +\n    geom_text_repel() +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in millions (log scale)\") +\n    ylab(\"Total number of murders (log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\") +\n    scale_color_discrete(name = \"Region\") +\n    theme_economist()"
  },
  {
    "objectID": "series/Data Visualization/about.html#other-examples",
    "href": "series/Data Visualization/about.html#other-examples",
    "title": "Data Visualization",
    "section": "\n3.9 Other Examples",
    "text": "3.9 Other Examples\n\n3.9.1 Textbook links:\n\nTextbook section on histograms\nTextbook section on density plots\nTextbook section on grids of plots\n\n3.9.2 Key points\n\ngeom_histogram() creates a histogram. Use the binwidth argument to change the width of bins, the fill argument to change the bar fill color, and the col argument to change bar outline color.\ngeom_density() creates smooth density plots. Change the fill color of the plot with the fill argument.\ngeom_qq() creates a quantile-quantile plot. This geometry requires the sample argument. By default, the data are compared to a standard normal distribution with a mean of 0 and standard deviation of 1. This can be changed with the dparams argument, or the sample data can be scaled.\nPlots can be arranged adjacent to each other using the grid.arrange() function from the gridExtra package. First, create the plots and save them to objects (p1, p2, …). Then pass the plot objects to grid.arrange().\n\n3.9.3 Code: Histograms in ggplot2\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\n\n# define p\np <- heights %>% \n  filter(sex == \"Male\") %>% \n  ggplot(aes(x=height))\n\n\n# basic histograms\np + geom_histogram() + ggtitle(\"binwidth is default\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\np + geom_histogram(binwidth = 1) + ggtitle(\"binwidth is 1\")\n\n\n\n# histogram with blue fill, black outline, labels and title\np + geom_histogram(binwidth = 1, fill =\"blue\", col = \"black\") + \n  xlab(\"Male heights in inches\") +\n  ggtitle(\"histogram\")\n\n\n\n\n\n3.9.4 Code: Smooth density plots in ggplot2\n\np + geom_density()\n\n\n\np + geom_density(fill = \"blue\", col = \"red\") +\n  xlab(\"Male heights in inches\") +\n  ylab(\"proportion of Male heights\") +\n  ggtitle(\"Male heights distribution\")\n\n\n\n\n\n3.9.5 Code: Quantile-quantile plots in ggplot2\n\n# basic QQ-plot\np <- heights %>% filter(sex == \"Male\") %>% \n  ggplot(aes(sample = height))\np + geom_qq()\n\n\n\n# QQ-plot against a normal distribution with same mean/sd as data\nparams <- heights %>% \n  filter(sex == \"Male\") %>% \n  summarize(mean = mean(height), sd = sd(height))\np + geom_qq(dparams = params) +\n  geom_abline()\n\n\n\n# QQ-plot of scaled data against the standard normal distribution\nheights %>% \n  ggplot(aes(sample = scale(height))) +\n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n# define plots p1, p2, p3\np <- heights %>% filter(sex == \"Male\") %>% ggplot(aes(x = height))\np1 <- p + geom_histogram(binwidth = 1, fill = \"blue\", col = \"black\")\np2 <- p + geom_histogram(binwidth = 2, fill = \"blue\", col = \"black\")\np3 <- p + geom_histogram(binwidth = 3, fill = \"blue\", col = \"black\")\n\n\n# arrange plots next to each other in 1 row, 3 columns\nlibrary(gridExtra)\n\n\ngrid.arrange(p1, p2, p3, ncol = 3)"
  },
  {
    "objectID": "series/Data Visualization/about.html#overview-2",
    "href": "series/Data Visualization/about.html#overview-2",
    "title": "Data Visualization",
    "section": "\n4.1 Overview",
    "text": "4.1 Overview\nAfter completing Gapminder, you will: - understand how Hans Rosling and the Gapminder Foundation use effective data visualization to convey data-based trends.\n\nbe able to apply the ggplot2 techniques from the previous section to answer questions using data.\nunderstand how fixed scales across plots can ease comparisons.\nbe able to modify graphs to improve data visualization."
  },
  {
    "objectID": "series/Data Visualization/about.html#introduction-to-gapminder",
    "href": "series/Data Visualization/about.html#introduction-to-gapminder",
    "title": "Data Visualization",
    "section": "\n4.2 Introduction to Gapminder",
    "text": "4.2 Introduction to Gapminder\nCase study: Trends in World Health and Economics\nData Source form Gapminder\nWe will use this data to answer the following questions about World Health and Economics: - Is it still fair to consider the world as divided into the West and the developing world? - Has income inequality across countries worsened over the last 40 years?"
  },
  {
    "objectID": "series/Data Visualization/about.html#gapminder-dataset",
    "href": "series/Data Visualization/about.html#gapminder-dataset",
    "title": "Data Visualization",
    "section": "\n4.3 Gapminder Dataset",
    "text": "4.3 Gapminder Dataset\n\n4.3.1 Key Points\n\nA selection of world health and economics statistics from the Gapminder project can be found in the dslabs package as data(gapminder).\nMost people have misconceptions about world health and economics, which can be addressed by considering real data.\n\n4.3.2 Code\n\nlibrary(dslabs)\ndata(\"gapminder\")\n\n\nhead(gapminder)\n\n              country year infant_mortality life_expectancy fertility\n1             Albania 1960           115.40           62.87      6.19\n2             Algeria 1960           148.20           47.50      7.65\n3              Angola 1960           208.00           35.98      7.32\n4 Antigua and Barbuda 1960               NA           62.97      4.43\n5           Argentina 1960            59.87           65.39      3.11\n6             Armenia 1960               NA           66.86      4.55\n  population          gdp continent          region\n1    1636054           NA    Europe Southern Europe\n2   11124892  13828152297    Africa Northern Africa\n3    5270844           NA    Africa   Middle Africa\n4      54681           NA  Americas       Caribbean\n5   20619075 108322326649  Americas   South America\n6    1867396           NA      Asia    Western Asia\n\nnames(gapminder)\n\n[1] \"country\"          \"year\"             \"infant_mortality\" \"life_expectancy\" \n[5] \"fertility\"        \"population\"       \"gdp\"              \"continent\"       \n[9] \"region\"          \n\n\n\ngapminder %>% \n  filter(year == 2015 & country %in% c(\"Sri Lanka\", \"Turkey\")) %>% \n  select(country, infant_mortality)\n\n    country infant_mortality\n1 Sri Lanka              8.4\n2    Turkey             11.6"
  },
  {
    "objectID": "series/Data Visualization/about.html#life-expectancy-and-fertility-rates",
    "href": "series/Data Visualization/about.html#life-expectancy-and-fertility-rates",
    "title": "Data Visualization",
    "section": "\n4.4 Life Expectancy and Fertility Rates",
    "text": "4.4 Life Expectancy and Fertility Rates\n\n4.4.1 Key Points\n\n\nA prevalent worldview is that the world is divided into two groups of countries:\n\nWestern world: high life expectancy, low fertility rate\nDeveloping world: lower life expectancy, higher fertility rate\n\n\nGapminder data can be used to evaluate the validity of this view.\nA scatterplot of life expectancy versus fertility rate in 1962 suggests that this viewpoint was grounded in reality 50 years ago. Is it still the case today?\n\n4.4.2 Code\n\n# basic scatterplot of life expectancy versus fertility\nds_theme_set() # set plot theme\nfilter(gapminder, year == 1962) %>% \n  ggplot(aes(fertility, life_expectancy)) +\n  geom_point()\n\n\n\n# add color as continent\nfilter(gapminder, year == 1962) %>% \n  ggplot(aes(fertility, life_expectancy, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "series/Data Visualization/about.html#faceting",
    "href": "series/Data Visualization/about.html#faceting",
    "title": "Data Visualization",
    "section": "\n4.5 Faceting",
    "text": "4.5 Faceting\n\n4.5.1 Key Points\n\nFaceting makes multiple side-by-side plots stratified by some variable. This is a way to ease comparisons.\nThe facet_grid() function allows faceting by up to two variables, with rows faceted by one variable and columns faceted by the other variable. To facet by only one variable, use the dot operator as the other variable.\nThe facet_wrap() function facets by one variable and automatically wraps the series of plots so they have readable dimensions.\nFaceting keeps the axes fixed across all plots, easing comparisons between plots.\nThe data suggest that the developing versus Western world view no longer makes sense in 2012.\n\n ggplot2-分面(facet) 一页多图数据可视化章节学习facet\n\n4.5.2 Code\n\n# facet by continent and year\nfilter(gapminder, year %in% c(1962, 2012)) %>% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(continent ~ year)\n\n\n\n# facet by year only \nfilter(gapminder, year %in% c(1962, 2012)) %>% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(. ~ year)\n\n\n\n# facet by year, plots wrapped onto multiple rows\nyears <- c(1962, 1980, 1990, 2000, 2012)\ncontinents <- c(\"Europ\", \"Asia\")\ngapminder %>% \n  filter(year %in% years & continent %in% continent) %>% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_wrap(. ~ year)"
  },
  {
    "objectID": "series/Data Visualization/about.html#time-series-plots",
    "href": "series/Data Visualization/about.html#time-series-plots",
    "title": "Data Visualization",
    "section": "\n4.6 Time Series Plots",
    "text": "4.6 Time Series Plots\n\n4.6.1 Key Points\n\nTime series plots have time on the x-axis and a variable of interest on the y-axis.\nThe geom_line() geometry connects adjacent data points to form a continuous line. A line plot is appropriate when points are regularly spaced, densely packed and from a single data series.\nYou can plot multiple lines on the same graph. Remember to group or color by a variable so that the lines are plotted independently.\nLabeling is usually preferred over legends. However, legends are easier to make and appear by default. Add a label with geom_text(), specifying the coordinates where the label should appear on the graph.\n\n4.6.2 Code: Single Time Series\n\n# scatterplot of US fertility by year\ngapminder %>% \n  filter(country == \"United States\") %>% \n  ggplot(aes(year, fertility)) +\n  geom_point()\n\n\n\n# line plot of US fertility by year\ngapminder %>% \n  filter(country == \"United States\") %>% \n  ggplot(aes(year, fertility)) +\n  geom_line()\n\n\n\n\n\n4.6.3 Code: Multiple Time Series\n\n# line plot fertility time series for two countries- only one line (incorrect)\ncountries <- c(\"South Korea\", \"Germany\")\ngapminder %>% filter(country %in% countries) %>%\n    ggplot(aes(year, fertility)) +\n    geom_line()\n\n\n\n# line plot fertility time series for two countries - one line per country\ngapminder %>% filter(country %in% countries) %>%\n    ggplot(aes(year, fertility, group = country)) +\n    geom_line()\n\n\n\n# fertility time series for two countries - lines colored by country\ngapminder %>% filter(country %in% countries) %>%\n    ggplot(aes(year, fertility, col = country)) +\n    geom_line()\n\n\n\n\n\n4.6.4 Code: Adding text labels to a plot\n\n\n\n\n\n\nNote\n\n\n\nlabels data frame as the data to ensure where to start label text \n\n\n\n# life expectancy time series - lines colored by country and labeled, no legend\nlabels <- data.frame(country = countries, x = c(1975, 1965), y = c(60, 72))\ngapminder %>% filter(country %in% countries) %>%\n    ggplot(aes(year, life_expectancy, col = country)) +\n    geom_line() +\n    geom_text(data = labels, aes(x, y, label = country), size = 5) +\n    theme(legend.position = \"none\")"
  },
  {
    "objectID": "series/Data Visualization/about.html#transformations",
    "href": "series/Data Visualization/about.html#transformations",
    "title": "Data Visualization",
    "section": "\n4.7 Transformations",
    "text": "4.7 Transformations\n\n4.7.1 Key Points\n\nWe use GDP data to compute income in US dollars per day, adjusted for inflation.\nLog transformations covert multiplicative changes into additive changes.\ncommon transformations are the log base 2 transformation and the log base 10 transformation. The choice of base depends on the range of the data. The natural log is not recommended for visualization because it is difficult to interpret.\nThe mode of a distribution is the value with the highest frequency. The mode of a normal distribution is the average. A distribution can have multiple local modes.\nThere are two ways to use log transformations in plots: transform the data before plotting or transform the axes of the plot. Log scales have the advantage of showing the original values as axis labels, while log transformed values ease interpretation of intermediate values between labels.\nScale the x-axis using scale_x_continuous() or scale_x_log10() layers in ggplot2. Similar functions exist for the y-axis.\nIn 1970, income distribution is bimodal, consistent with the dichotomous Western versus developing worldview.\n\n4.7.2 Code\n\n# add dollars per day variable\ngapminder <- gapminder %>% \n  mutate(dollars_per_day = gdp/population/365)\n\n# histogram of dollars per day\npast_year <- 1970\ngapminder %>% \n  filter(year == past_year & !is.na(gdp)) %>% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n# repeat histogram with log2 scaled data\ngapminder %>%\n    filter(year == past_year & !is.na(gdp)) %>%\n    ggplot(aes(log2(dollars_per_day))) +\n    geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n# repeat histogram with log2 scaled x-axis\ngapminder %>%\n    filter(year == past_year & !is.na(gdp)) %>%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\")"
  },
  {
    "objectID": "series/Data Visualization/about.html#stratify-and-boxplot",
    "href": "series/Data Visualization/about.html#stratify-and-boxplot",
    "title": "Data Visualization",
    "section": "\n4.8 Stratify and Boxplot",
    "text": "4.8 Stratify and Boxplot\n\n4.8.1 Key Points\n\nMake boxplots stratified by a categorical variable using the geom_boxplot() geometry.\nRotate axis labels by changing the theme through element_text(). You can change the angle and justification of the text labels.\nConsider ordering your factors by a meaningful value with the reorder function, which changes the order of factor levels based on a related numeric vector. This is a way to ease comparisons.\nShow the data by adding data points to the boxplot with a geom_point layer. This adds information beyond the five-number summary to your plot, but too many data points it can obfuscate your message.\n\n4.8.2 Code: Boxplot of GDP by region\n\n# add dollars per day variable\ngapminder <- gapminder %>% \n  mutate(dollars_per_day = gdp/population/365)\n\n# number of regions\nlength(levels(gapminder$region))\n\n[1] 22\n\n# boxplot of GDP by region in 1970\npast_year <- 1970\np <- gapminder %>% \n     filter(year == past_year & !is.na(gdp)) %>% \n     ggplot(aes(region, dollars_per_day))\np + geom_boxplot()\n\n\n\n# roation name on x-axis\np + geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n4.8.3 Code: The reorder function\n\n\n\n\n\n\nTip\n\n\n\nReorder a variable with ggplot2\n\n\n\n# by default, factor order is alphabetical\nfac <- factor(c(\"Asia\", \"Asia\", \"West\", \"West\", \"West\"))\nlevels(fac)\n\n[1] \"Asia\" \"West\"\n\n# reorder factor by the category means\nvalue <- c(10, 11, 12, 6, 4)\nfac <- reorder(fac, value, FUN = mean)\nlevels(fac)\n\n[1] \"West\" \"Asia\"\n\n\n\n4.8.4 Code: Enhanced boxplot ordered by median income, scaled, and showing data\n\n# reorder by median income and color by continent \np <- gapminder %>%\n    filter(year == past_year & !is.na(gdp)) %>%\n    mutate(region = reorder(region, dollars_per_day, FUN = median)) %>%  # reorder\n    ggplot(aes(region, dollars_per_day, fill = continent)) + # color by continent \n    geom_boxplot() +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n    xlab(\"\")\np\n\n\n\n# log2 scale y-axis\np + scale_y_continuous(trans = \"log2\")\n\n\n\n# add data points\np + scale_y_continuous(trans = \"log2\") + geom_point(show.legend = FALSE)"
  },
  {
    "objectID": "series/Data Visualization/about.html#comparing-distributions",
    "href": "series/Data Visualization/about.html#comparing-distributions",
    "title": "Data Visualization",
    "section": "\n4.9 Comparing Distributions",
    "text": "4.9 Comparing Distributions\n\n\n\n\n\n\nImportant\n\n\n\nintersect(交集);union(并集);setdiff(找不同);setequal(判断相同)\n\n\n\n4.9.1 Key Points\n\nUse intersect to find the overlap between two vectors.\nTo make boxplots where grouped variables are adjacaent, color the boxplot by a factor instead of faceting by that factor. This is a way to ease comparisions.\nThe data suggest that the income gap between rich and poor countries has narrowed, not expended.\n\n4.9.2 Code: Histogram of income in West versus developing world, 1970 and 2010\n\n# add dollars per day variable and define past year\ngapminder <- gapminder %>% \n  mutate(dollars_per_day = gdp/population/365)\npast_year <- 1970\n\n# define Western countries\nwest <- c(\"Western Europe\", \"Northern Europe\", \"Southern Europe\", \"Northern America\", \"Australia and New Zealand\")\n\n# facet by West vs Devloping \ngapminder %>% \n  filter(year == past_year & !is.na(gdp)) %>% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %>% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(. ~group)\n\n\n\n# facet by West/Developing and year\npresent_year <- 2010\ngapminder %>%\n    filter(year %in% c(past_year, present_year) & !is.na(gdp)) %>%\n    mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %>%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\") +\n    facet_grid(year ~ group)\n\n\n\n\n\n4.9.3 Code: Income distribution of West verseus Developing world, only countries with data\n\n# define countries that have data available in both years\ncountry_list_1 <- gapminder %>% \n  filter(year == past_year & !is.na(dollars_per_day)) %>% .$country\n\ncountry_list_2 <- gapminder %>% \n  filter(year == present_year & !is.na(dollars_per_day)) %>% .$country\n\ncountry_list <- intersect(country_list_1, country_list_2)\n\n# make histogram including only countries with data availabe in both years\ngapminder %>% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %>% # keep only selected countries\n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %>% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(year ~ group)\n\n\n\n\n\n4.9.4 Code: Boxplots of income in West versus Developing world, 1970 and 2010\n\np <- gapminder %>% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %>%\n  mutate(region = reorder(region, dollars_per_day, FUN = median)) %>% \n  ggplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  xlab(\"\") + scale_y_continuous(trans = \"log2\") \n\np + geom_boxplot(aes(region, dollars_per_day, fill = continent)) +\n  facet_grid(year ~ .)\n\n\n\n# arrange matching boxplots next to each other, colored by year\np + geom_boxplot(aes(region, dollars_per_day, fill = factor(year)))"
  },
  {
    "objectID": "series/Data Visualization/about.html#density-plots",
    "href": "series/Data Visualization/about.html#density-plots",
    "title": "Data Visualization",
    "section": "\n4.10 Density Plots",
    "text": "4.10 Density Plots\n\n\n\n\n\n\nTip\n\n\n\n\ndplyr处理数据时常用的的函数\n在 R Dplyr 包中使用 case when 语句\n\n\n\n\n4.10.1 Key Points\n\nChange the y-axis of density plots to variable counts using ..count.. as the y argument.\nThe case_when() function defines a factor whose levels are defined by a variety of logical operations to group data.\nPlot stacked density plots using position=\"stack\".\nDefine a weight aesthetic mapping to change the relative weights of density plots-for example, this allow weighting of plots by population rather than number of countries.\n\n4.10.2 Code: Faceted smooth density plots\n\n# see the code below the previous video for variable definitions\n\n# smooth density plots - area under each curve adds to 1\ngapminder %>% \n  filter(year == past_year & country %in% country_list) %>% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %>% group_by(group) %>% \n  summarize(n = n()) %>% knitr::kable()\n\n\n\ngroup\nn\n\n\n\nDeveloping\n87\n\n\nWest\n21\n\n\n\n\n# smooth density plots - variable counts on y-axis\np <- gapminder %>% \n  filter(year == past_year & country %in% country_list) %>% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %>%\n  ggplot(aes(dollars_per_day, y = ..count.., fill = group)) +\n  scale_x_continuous(trans = \"log2\")\np + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(year ~ .)\n\n\n\n\n\n4.10.3 Code: Add new region group with case_when\n\n# add group as a factor, grouping regions\ngapminder <- gapminder %>% \n  mutate(group = case_when(\n    .$region %in% west ~ \"West\",\n    .$region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\", \n    .$region %in% c(\"Caribbean\", \"Central America\", \"South America\") ~ \"Latin America\",\n    .$continent == \"Africa\" & .$region != \"Northern Africa\" ~ \"Sub-Saharan Africa\", TRUE ~ \"Others\"))\n\n# reorder factor levels\ngapminder <- gapminder %>% \n  mutate(group = factor(group, levels = c(\"Others\", \"Latin America\", \"East Asia\", \"Sub-Saharan Africa\", \"West\")))\n\n\n4.10.4 Code: Stacked density plot\n\n# note you must redefine p with the new gapminder object first\np <- gapminder %>% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %>% \n  ggplot(aes(dollars_per_day, fill = group)) +\n  scale_x_continuous(trans = \"log2\")\n\n# stacked density plot\np + geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") +\n  facet_grid(year ~ .)\n\n\n\n\n\n4.10.5 Code: Weighted stacked density plot\n\ngapminder %>% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %>% \n  group_by(year) %>% \n  mutate(weight = population/sum(population*2)) %>% \n  ungroup() %>% \n  ggplot(aes(dollars_per_day, fill = group, weight = weight)) +\n  scale_x_continuous(trans = \"log2\") +\n  geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") + facet_grid(year ~ .)"
  },
  {
    "objectID": "series/Data Visualization/about.html#ecological-fallacy",
    "href": "series/Data Visualization/about.html#ecological-fallacy",
    "title": "Data Visualization",
    "section": "\n4.11 Ecological Fallacy",
    "text": "4.11 Ecological Fallacy\n\n4.11.1 Key Points"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Stats & R",
    "section": "",
    "text": "💌 Get In Touch\n\n\n\n\n\nThanks in advance for contacting me.\nIn order for me to answer you as soon as possible, here are the best communication methods:\n\nDue to the increasing number of questions received, responding to each of them by email has become unmanageable and unproductive. Therefore, if you have a question, I invite you to add it as a comment at the end of the corresponding article. This way, other readers can benefit from the discussion and that saves me from answering the same thing several times. Questions by email will not be answered (I will redirect you to the comments).\nFor mistakes, bugs or inconsistencies—and that can happen, we are all human after all—you can inform me about them by raising an issue on GitHub. If you are familiar with GitHub, you can even edit the corresponding file and propose a pull request so I can quickly include your changes.\nFor a quick answer to your question, make sure to first check the comments from other readers. Your question may have already been answered.\n\nThank you !!!\n\n\n\n\n  Contact Form\n  \n\n\n  \n    Contact Form\n    \n      \n        \n          First Name:\n          \n        \n        \n          Last Name:\n          \n        \n      \n      \n        Email Address:\n        \n      \n      \n        Message:\n        \n      \n      \n        Submit\n        Reset"
  },
  {
    "objectID": "posts/Install R and Rstudio on Mac/about.html",
    "href": "posts/Install R and Rstudio on Mac/about.html",
    "title": "Install R and Rstudio on Mac",
    "section": "",
    "text": "1 什么是R\nR是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。简单来说，R是一门统计计算语言，是一套开源的数据分析解决方案。\n\n2 什么是Rstudio\nRStudio是为R语言设计的一种跨平台集成开发环境。其特色包括可客制化的软件套件视觉化界面与同团队开发的一系列数据可视化与出版工具。RStudio有免费的自由软件版本及收费的专业版本，并分为在本地电脑上执行的桌面版和与在服务器上执行而可由浏览器连接后使用的服务器版。\n\n3 前提\n安装顺序(不能颠倒)\n\nR语言\nRstudio\n\nR是Rstudio的基础，必须先安装R，再安装Rstudio。\n\n\n\n\n\n\nNote\n\n\n\nR is a programming language and environment for statistical computing and graphics, while RStudio is an integrated development environment (IDE) for R. Installing R first allows the computer to recognize the R language, and then RStudio can be installed on top of it to provide a user-friendly interface and additional tools for working with R. It is not necessary to install R first but it is a good practice as some features of RStudio are dependent on R.\n\n\n\n\n4 R语言安装\n\n官网安装包下载地址：https://cran.r-project.org/\n\n点击MacOS对应选项， 下方红框标出的地方\n\n\n\n在下载界面点击base，下方红框标出的地方\n\n\n\n自行选择下载R语言版本， 下载最新的版本为妙\n\n\n下载完成， 在”Finder→下载”中点击pkg文件， 一直按下一步可安装完成。\n\n5 Rstudio安装\n\n官网安装包下载地址：https://posit.co/download/rstudio-desktop/#download\n\n点击下方红色标出地方，直接下载\n\n\n下载完成， 在”Finder→下载”中点击dmg文件， 将app拖入application中即可。\n安装完成\n\n6 在Rstudio中创建新项目\n\n\n创建新project。具体方法如下图所示， 依次点击File->New Project => New Directory->New Project->输入Directory name（注意要用英文，别用中文）\n\n\n\n\n\n\n创建好，就会出现下图所示\n\n\n\n7 测试R\n\n现在测试一下我们安装的的R语言环境\n\n\nheight <- c(145, 167, 176, 123, 150)\nweight <- c(51, 63, 64, 40, 55)\ncor(height, weight)\n\n[1] 0.9893769\n\nplot(height,weight, type = \"p\")\n\n\n\n\n\n8 测试结果\n\n结果输出一切正常"
  },
  {
    "objectID": "posts/Dynamic Graph/about.html",
    "href": "posts/Dynamic Graph/about.html",
    "title": "Dynamic Graph",
    "section": "",
    "text": "Here is an example shows how to use gganmate package to make a dynamic graph."
  },
  {
    "objectID": "posts/Dynamic Graph/about.html#data-from-mtcars",
    "href": "posts/Dynamic Graph/about.html#data-from-mtcars",
    "title": "Dynamic Graph",
    "section": "Data from mtcars",
    "text": "Data from mtcars\n\nlibrary(ggplot2)\nlibrary(gganimate)\n\nggplot(mtcars, aes(factor(cyl), mpg)) + \n  geom_boxplot() + \n  # Here comes the gganimate code\n  transition_states(\n    gear,\n    transition_length = 2,\n    state_length = 1\n  ) +\n  enter_fade() + \n  exit_shrink() +\n  ease_aes('sine-in-out')"
  },
  {
    "objectID": "posts/welcome/about.html",
    "href": "posts/welcome/about.html",
    "title": "Welcome",
    "section": "",
    "text": "This is my first blog on Stats & R. Hope you will find some joys here !!!"
  },
  {
    "objectID": "posts/Christmas Tree/about.html",
    "href": "posts/Christmas Tree/about.html",
    "title": "Christmas Tree",
    "section": "",
    "text": "Let us use ggplot2 to make a Christmas Tree.\nCode\n\nrm(list = ls())\nlibrary(ggplot2)\n\n# create data\nx <- c(8,7,6,7,6,5,6,5,4,5,4,3,4,3,2,3,2,1,0.5,0.1)\n\ndat1 <- data.frame(x1 = 1:length(x), x2 = x)\ndat2 <- data.frame(x1 = 1:length(x), x2 = -x)\ndat1$xvar <- dat2$xvar <- NA\ndat1$yvar <- dat2$yvar <- NA\ndat1$siz <- dat2$siz <- NA\ndat1$col <- dat2$col <- NA\n\n# set threshold for christmas balls\ndec_threshold = -0.5\n\n# create random places, sizes and colors for christmas balls\nset.seed(2512)\nfor (row in 1:nrow(dat1)){\n\nif (rnorm(1) > dec_threshold){\n\ndat1$xvar[row] <- row\ndat1$yvar[row] <- sample(1:dat1$x2[row]-1,1)\ndat1$siz[row] <- runif(1,0.5,1.5)\ndat1$col[row] <- sample(1:5, 1)\n}\n\nif (rnorm(1) > dec_threshold){\n\ndat2$xvar[row] <- row\ndat2$yvar[row] <- sample(1:dat2$x2[row],1)\ndat2$siz[row] <- runif(1,0.5,1.5)\ndat2$col[row] <- sample(1:5, 1)\n}\n}\n\n# plot the christmas tree\nggplot() +\ngeom_bar(data = dat1, aes(x=x1, y=x2),stat = \"identity\", fill = '#31a354') +\ngeom_bar(data = dat2, aes(x=x1, y=x2),stat = \"identity\", fill = '#31a354') +\ngeom_point(data = dat1,aes(x = xvar, y = yvar, size = siz, colour = as.factor(col)) ) +\ngeom_point(data = dat2,aes(x = xvar, y = yvar, size = siz, colour = as.factor(col)) ) +\ncoord_flip() + theme_minimal()+ theme(legend.position=\"none\",\naxis.title.x=element_blank(),\naxis.text.x=element_blank(),\naxis.ticks.x=element_blank(),\naxis.title.y=element_blank(),\naxis.text.y=element_blank(),\naxis.ticks.y=element_blank()) +\nggtitle('Merry Christmas') +\ntheme(plot.title = element_text(color = \"red\", hjust = 0.5))"
  },
  {
    "objectID": "series.html",
    "href": "series.html",
    "title": "Stats & R",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nProbability\n\n\n\n\n\n\n\nData Science\n\n\nProbability\n\n\n\n\nData Science-Probability\n\n\n\n\n\n\nDec 7, 2022\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nData Visualization\n\n\n\n\n\n\n\nData Science\n\n\nData Visualization\n\n\n\n\nData Science-Data Visualization\n\n\n\n\n\n\nDec 1, 2022\n\n\n36 min\n\n\n\n\n\n\n  \n\n\n\n\nR Basic\n\n\n\n\n\n\n\nData Science\n\n\nR Basic\n\n\n\n\nData Science-R Basic\n\n\n\n\n\n\nNov 27, 2022\n\n\n31 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stats & R",
    "section": "",
    "text": "Welcome to Stats & R!!!\nThis is a personal website with the contents of statistics and the open-source R language, aiming to facilitate academic exchanges and better promote myself.\nIf you are new to this site, here are some useful suggestions that you can do.\n\nOn the posts page, some interesting ideas (how to use R to make a 3D Christmas tree, etc.) for daily life will be presented.\nThe about page is a good place where you can quickly get to know who I am and what I am doing now.\nThe series page will display my independent projects and R language study notes.\nIf you have any questions, please go to the contact page to get in touch with me directly.\n\nThanks again for coming to my personal website.😘\n\n\n📮 Recent Posts\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nJan 19, 2023\n\n\nInstall R and Rstudio on Mac\n\n\n\n\nDec 1, 2022\n\n\nDynamic Graph\n\n\n\n\nNov 30, 2022\n\n\nChristmas Tree\n\n\n\n\nNov 27, 2022\n\n\nWelcome\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Stats & R",
    "section": "",
    "text": "Hi, I’ m Ning and I’m a potential data analyst.\nMy current focus is statistics, R-based data analysis and corporate-related political risk issues.\nMy background is in Accountancy. If you have any doubts about corporate auditing issues, maybe i can help you.\nI really hate graphical interface data analysis software, because it always gives me extra results that I didn’t ask for.\nMy current short-term goal is to publish my first peer-reviewed paper and start my PhD by 2023.\nIn my free time, I like listening to music, hiking and reading. If you also like these activities, please feel free to contact me.\n\n\nMassey University, Auckland | Master in Accountancy | February 2019 - June 2020\n\n\n\nLife Maid Easy | Head Marketing | December 2020 - present"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Stats & R",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nInstall R and Rstudio on Mac\n\n\n\ntutorial\n\n\n\nA tutorial for R and Rstudio installation on Mac\n\n\n\nNING LI\n\n\nJan 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic Graph\n\n\n\ncode\n\n\nanalysis\n\n\n\nMake a dynamic graph by gganmate\n\n\n\nNING LI\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChristmas Tree\n\n\n\ncode\n\n\n\nMerry Christmas Everyone!!!\n\n\n\nNING LI\n\n\nNov 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\n\nnews\n\n\n\nWelcome !!!\n\n\n\nNING LI\n\n\nNov 27, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "success.html",
    "href": "success.html",
    "title": "Stats & R",
    "section": "",
    "text": "Form Submission Success\n  \n\n\n  \n    Thank You!\n    \n      Your form has been submitted successfully.\n      I will be in touch with you soon.\n      Back to Home"
  }
]